#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–°ã—ã„APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå¯¾å¿œç‰ˆ - çµ±åˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Places API (New) v1ã‚’ä½¿ç”¨ã—ãŸæœ€æ–°ç‰ˆå®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ 
Clean Architectureæº–æ‹ ãƒ»ä¾å­˜æ€§æ³¨å…¥å¯¾å¿œç‰ˆ
Phase 2æ”¹å–„: éåŒæœŸå‡¦ç†ãƒ»ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–çµ±åˆ
"""

import argparse
import sys
import asyncio
from datetime import datetime
from pathlib import Path
from typing import Optional

# ãƒ‘ã‚¹è¨­å®š
current_dir = Path(__file__).parent
scraper_root = current_dir.parent.parent
sys.path.insert(0, str(scraper_root))

# Add shared path for direct imports
shared_path = scraper_root / "shared"
sys.path.insert(0, str(shared_path))

# æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¯¾å¿œã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from shared.config import ScraperConfig
from shared.container import DIContainer, create_container
from shared.logger import get_logger, configure_logging, LoggingConfig
from shared.exceptions import ConfigurationError, ValidationError
from application.workflows.data_processing_workflow import DataProcessingWorkflow
from shared.types.core_types import CategoryType

# Phase 2æ”¹å–„: æ–°ã—ã„å…±æœ‰ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
from shared.error_handler import ErrorHandler, ErrorSeverity, ErrorCategory
from shared.performance_monitor import PerformanceMonitor

# å®šæ•°å®šç¾©
class ScraperConstants:
    """ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼å®Ÿè¡Œã®å®šæ•°å®šç¾©"""
    COST_PER_QUERY = 0.017  # USD per query
    ESTIMATED_TIME_PER_QUERY = 1.2  # seconds per query
    SECONDS_TO_MINUTES = 60
    DEFAULT_ENV_FILE = 'config/.env'
    ERROR_DISPLAY_LIMIT = 3  # ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã®æœ€å¤§ä»¶æ•°

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å®šæ•°
    PROCESSING_COMPLETE_MSG = "ğŸ‰ å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼"
    PROCESSING_PARTIAL_MSG = "âš ï¸ å‡¦ç†ãŒéƒ¨åˆ†çš„ã«å®Œäº†ã—ã¾ã—ãŸ"
    ASYNC_PROCESSING_COMPLETE_MSG = "ğŸ‰ éåŒæœŸå‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼"
    ASYNC_PROCESSING_PARTIAL_MSG = "âš ï¸ éåŒæœŸå‡¦ç†ãŒéƒ¨åˆ†çš„ã«å®Œäº†ã—ã¾ã—ãŸ"

class DataFileConfig:
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®š"""
    RESTAURANTS = 'data/restaurants_merged.txt'
    PARKINGS = 'data/parkings_merged.txt'
    TOILETS = 'data/toilets_merged.txt'

    @classmethod
    def get_file_mapping(cls) -> dict[str, str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸ã‚’å–å¾—"""
        return {
            'restaurants': cls.RESTAURANTS,
            'parkings': cls.PARKINGS,
            'toilets': cls.TOILETS
        }

class UserInteraction:
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®æŠ½è±¡åŒ–ã‚¯ãƒ©ã‚¹ï¼ˆãƒ†ã‚¹ã‚¿ãƒ“ãƒªãƒ†ã‚£å‘ä¸Šï¼‰"""

    @staticmethod
    def confirm_execution(message: str = "å®Ÿè¡Œã‚’ç¶šã‘ã¾ã™ã‹ï¼Ÿ") -> bool:
        """å®Ÿè¡Œç¢ºèªã‚’å–å¾—"""
        confirmation = input(f"\n{message} (y/N): ")
        return confirmation.lower() == 'y'

class ScraperCLI:
    """æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¯¾å¿œCLIå®Ÿè¡Œã‚¯ãƒ©ã‚¹ - Phase 2æ”¹å–„ç‰ˆ"""

    def __init__(self, config: ScraperConfig, container: DIContainer):
        """CLIåˆæœŸåŒ– - Phase 2æ”¹å–„ç‰ˆ"""
        self._config = config
        self._container = container
        self._logger = get_logger(__name__)

        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å–å¾—
        self._workflow = self._container.get(DataProcessingWorkflow)

        # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®šã‚’ä½¿ç”¨
        self.data_files = DataFileConfig.get_file_mapping()

        # Phase 2æ”¹å–„: æ–°ã—ã„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        self._error_handler = ErrorHandler("ScraperCLI")
        self._performance_monitor = PerformanceMonitor("ScraperCLI")

    def validate_environment(self) -> bool:
        """ç’°å¢ƒè¨­å®šã®æ¤œè¨¼"""
        try:
            # API ã‚­ãƒ¼ã®æ¤œè¨¼
            if not self._config.google_api.places_api_key:
                self._logger.error("Places API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False

            # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã®æ¤œè¨¼ï¼ˆè­¦å‘Šãƒ¬ãƒ™ãƒ«ï¼‰
            if not self._config.google_api.spreadsheet_id:
                self._logger.warning("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆGoogle Sheetsä¿å­˜ç„¡åŠ¹ï¼‰")

            # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ï¼ˆè­¦å‘Šãƒ¬ãƒ™ãƒ«ï¼‰
            if not self._config.google_api.service_account_path or not Path(self._config.google_api.service_account_path).exists():
                self._logger.warning("ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆGoogle Sheetsä¿å­˜ç„¡åŠ¹ï¼‰",
                                   path=self._config.google_api.service_account_path)

            self._logger.info("ç’°å¢ƒè¨­å®šæ¤œè¨¼å®Œäº†")
            return True

        except Exception as e:
            self._logger.error("ç’°å¢ƒè¨­å®šæ¤œè¨¼ã‚¨ãƒ©ãƒ¼", error=str(e))
            return False

    def validate_file(self, file_path: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª"""
        return self._workflow.validate_file(file_path)

    def count_queries(self, file_path: str) -> int:
        """ã‚¯ã‚¨ãƒªæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        return self._workflow.count_queries(file_path)

    def show_execution_plan(self, target: str, mode: str):
        """å®Ÿè¡Œè¨ˆç”»ã‚’è¡¨ç¤º"""
        print("ğŸ“Š å®Ÿè¡Œè¨ˆç”»")
        print(f"   ãƒ¢ãƒ¼ãƒ‰: {self.get_mode_description(mode)}")
        print(f"   å¯¾è±¡ãƒ‡ãƒ¼ã‚¿: {target}")

        total_queries = 0
        file_details = []

        if target == 'all':
            for category, file_path in self.data_files.items():
                if self.validate_file(file_path):
                    count = self.count_queries(file_path)
                    total_queries += count
                    file_details.append(f"   ğŸ“„ {category}: {count}ä»¶")
        else:
            if target in self.data_files:
                file_path = self.data_files[target]
                if self.validate_file(file_path):
                    count = self.count_queries(file_path)
                    total_queries += count
                    file_details.append(f"   ğŸ“„ {target}: {count}ä»¶")

        print(f"   ç·ã‚¯ã‚¨ãƒªæ•°: {total_queries}ä»¶")
        print(f"   æ¨å®šã‚³ã‚¹ãƒˆ: ${total_queries * ScraperConstants.COST_PER_QUERY:.3f} USD")
        print(f"   æ¨å®šå®Ÿè¡Œæ™‚é–“: {total_queries * ScraperConstants.ESTIMATED_TIME_PER_QUERY / ScraperConstants.SECONDS_TO_MINUTES:.1f} åˆ†")

        print("\nğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°:")
        for detail in file_details:
            print(detail)

        return total_queries

    def get_mode_description(self, mode: str) -> str:
        """ãƒ¢ãƒ¼ãƒ‰èª¬æ˜ã‚’å–å¾—"""
        descriptions = {
            'quick': 'é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼ˆCID URLã®ã¿å‡¦ç†ï¼‰',
            'standard': 'æ¨™æº–ãƒ¢ãƒ¼ãƒ‰ï¼ˆCID URL + é«˜ç²¾åº¦åº—èˆ—åï¼‰',
            'comprehensive': 'åŒ…æ‹¬ãƒ¢ãƒ¼ãƒ‰ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ + è©³ç´°æ¤œè¨¼ï¼‰'
        }
        return descriptions.get(mode, mode)

    def run_category(self, category: CategoryType, mode: str, dry_run: bool = False, separate_location: bool = True) -> bool:
        """ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®å‡¦ç†å®Ÿè¡Œ"""
        file_path: Optional[str] = self.data_files.get(category)

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å‹å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
        if file_path is None:
            self._logger.error("Unknown category specified", category=category)
            print(f"âŒ ä¸æ˜ãªã‚«ãƒ†ã‚´ãƒªã§ã™: {category}")
            return False

        if not self.validate_file(file_path):
            self._logger.error("Data file not found or empty", category=category, file_path=file_path)
            print(f"âŒ {category}ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ç©ºã§ã™: {file_path}")
            return False

        if dry_run:
            self._logger.info("Dry run completed", category=category)
            print(f"ğŸ“‹ {category}ãƒ‡ãƒ¼ã‚¿: ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Œäº†")
            return True

        print(f"\nğŸ”„ {category}ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­...")
        print(f"   å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: {self.get_mode_description(mode)}")

        try:
            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä½¿ç”¨ã—ã¦å‡¦ç†å®Ÿè¡Œï¼ˆãƒ¢ãƒ¼ãƒ‰æƒ…å ±ã‚’æ¸¡ã™ï¼‰
            result = self._workflow.run_category_processing(
                category=category,
                mode=mode,  # ãƒ¢ãƒ¼ãƒ‰æƒ…å ±ã‚’æ¸¡ã™
                dry_run=dry_run,
                separate_location=separate_location
            )

            if result.success:
                self._logger.info("Category processing completed successfully",
                                category=category, processed_count=result.processed_count)
                print(f"âœ… {category}ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†: {result.processed_count}ä»¶")
                return True
            else:
                self._logger.error("Category processing failed",
                                 category=category, error_count=len(result.errors))
                print(f"âŒ {category}ãƒ‡ãƒ¼ã‚¿å‡¦ç†å¤±æ•—: {len(result.errors)}å€‹ã®ã‚¨ãƒ©ãƒ¼")
                # ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã‚’åˆ¶é™
                for error in result.errors[:ScraperConstants.ERROR_DISPLAY_LIMIT]:
                    print(f"   - {error}")
                if len(result.errors) > ScraperConstants.ERROR_DISPLAY_LIMIT:
                    print(f"   ... ä»– {len(result.errors) - ScraperConstants.ERROR_DISPLAY_LIMIT} å€‹ã®ã‚¨ãƒ©ãƒ¼")
                return False

        except ValidationError as e:
            self._logger.error("Validation error during processing", category=category, error=str(e))
            print(f"âŒ {category}ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False
        except ConfigurationError as e:
            self._logger.error("Configuration error during processing", category=category, error=str(e))
            print(f"âŒ {category}è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
            return False
        except Exception as e:
            self._logger.error("Unexpected error during processing", category=category, error=str(e))
            print(f"âŒ {category}ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def run_unified_processing(self, target: str = 'all', mode: str = 'standard',
                             dry_run: bool = False, separate_location: bool = True) -> bool:
        """çµ±åˆå‡¦ç†å®Ÿè¡Œ"""

        # å®Ÿè¡Œè¨ˆç”»è¡¨ç¤º
        total_queries = self.show_execution_plan(target, mode)

        if total_queries == 0:
            print("âŒ å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False

        if dry_run:
            print(f"\n{'='*60}")
            print(ScraperConstants.PROCESSING_COMPLETE_MSG)
            print("ğŸ“ ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Œäº†ï¼ˆå®Ÿéš›ã®å‡¦ç†ã¯è¡Œã„ã¾ã›ã‚“ã§ã—ãŸï¼‰")
            print(f"ğŸ• çµ‚äº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            return True

        # å®Ÿè¡Œç¢ºèªï¼ˆãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ã§ãªã„å ´åˆã®ã¿ï¼‰
        if not dry_run and not UserInteraction.confirm_execution():
            self._logger.info("Processing cancelled by user")
            print("å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã—ãŸ")
            return False

        # å‡¦ç†å®Ÿè¡Œ
        success_count = 0
        total_count = 0

        if target == 'all':
            categories = list(self.data_files.keys())
        else:
            categories = [target] if target in self.data_files else []

        for category in categories:
            total_count += 1
            if self.run_category(category, mode, dry_run, separate_location):
                success_count += 1

        # çµæœè¡¨ç¤º
        print(f"\n{'='*60}")
        if success_count == total_count:
            print("ğŸ‰ å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        else:
            print("âš ï¸ å‡¦ç†ãŒéƒ¨åˆ†çš„ã«å®Œäº†ã—ã¾ã—ãŸ")

        print(f"ğŸ“Š æˆåŠŸ: {success_count}/{total_count} ã‚«ãƒ†ã‚´ãƒª")
        print(f"ğŸ• çµ‚äº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        return success_count > 0

    async def run_unified_processing_async(
        self,
        target: str = 'all',
        mode: str = 'standard',
        dry_run: bool = False,
        separate_location: bool = True
    ) -> bool:
        """çµ±åˆå‡¦ç†å®Ÿè¡Œ - éåŒæœŸç‰ˆ (Phase 2æ”¹å–„)"""

        with self._performance_monitor.measure_time("unified_processing_async"):
            try:
                # å®Ÿè¡Œè¨ˆç”»è¡¨ç¤º
                total_queries = self.show_execution_plan(target, mode)

                if total_queries == 0:
                    print("âŒ å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    return False

                if dry_run:
                    print(f"\n{'='*60}")
                    print(ScraperConstants.PROCESSING_COMPLETE_MSG)
                    print("ğŸ“ ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Œäº†ï¼ˆå®Ÿéš›ã®å‡¦ç†ã¯è¡Œã„ã¾ã›ã‚“ã§ã—ãŸï¼‰")
                    print(f"ğŸ• çµ‚äº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                    return True

                # å®Ÿè¡Œç¢ºèªï¼ˆãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ã§ãªã„å ´åˆã®ã¿ï¼‰
                if not dry_run and not UserInteraction.confirm_execution():
                    self._logger.info("Processing cancelled by user")
                    print("å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã—ãŸ")
                    return False

                # å‡¦ç†å®Ÿè¡Œ
                success_count = 0
                total_count = 0

                if target == 'all':
                    categories = list(self.data_files.keys())
                else:
                    categories = [target] if target in self.data_files else []

                print(f"\nğŸš€ éåŒæœŸå‡¦ç†é–‹å§‹ - {len(categories)}ã‚«ãƒ†ã‚´ãƒªã‚’ä¸¦åˆ—å‡¦ç†")

                # éåŒæœŸã‚«ãƒ†ã‚´ãƒªå‡¦ç†
                for category in categories:
                    total_count += 1
                    if await self._run_category_async(category, mode, dry_run, separate_location):
                        success_count += 1

                # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
                stats = self.get_processing_statistics()
                self._display_processing_statistics(stats)

                # çµæœè¡¨ç¤º
                print(f"\n{'='*60}")
                if success_count == total_count:
                    print(ScraperConstants.ASYNC_PROCESSING_COMPLETE_MSG)
                else:
                    print(ScraperConstants.ASYNC_PROCESSING_PARTIAL_MSG)

                print(f"ğŸ“Š æˆåŠŸ: {success_count}/{total_count} ã‚«ãƒ†ã‚´ãƒª")
                print(f"ğŸ• çµ‚äº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

                return success_count > 0

            except Exception as e:
                self._error_handler.handle_error(e, ErrorSeverity.HIGH, ErrorCategory.SYSTEM)
                print(f"âŒ éåŒæœŸå‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                return False

    async def _run_category_async(
        self,
        category: CategoryType,
        mode: str,
        dry_run: bool = False,
        separate_location: bool = True
    ) -> bool:
        """ã‚«ãƒ†ã‚´ãƒªåˆ¥å‡¦ç†å®Ÿè¡Œ - éåŒæœŸç‰ˆ"""

        with self._performance_monitor.measure_time(f"category_processing.{category}"):
            try:
                print(f"\nğŸ” {category}ãƒ‡ãƒ¼ã‚¿å‡¦ç†é–‹å§‹ï¼ˆéåŒæœŸãƒ¢ãƒ¼ãƒ‰ï¼‰")

                # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã«éåŒæœŸå‡¦ç†ã‚’æœ‰åŠ¹åŒ–ã—ã¦å®Ÿè¡Œ
                result = await self._workflow.process_category_async(
                    category=category,
                    mode=mode,
                    dry_run=dry_run,
                    separate_location=separate_location
                )

                if result.success:
                    print(f"âœ… {category}ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†")
                    print(f"ğŸ“Š å‡¦ç†ä»¶æ•°: {result.processed_count}")
                    if result.error_count > 0:
                        print(f"âš ï¸ ã‚¨ãƒ©ãƒ¼ä»¶æ•°: {result.error_count}")
                    return True
                else:
                    print(f"âŒ {category}ãƒ‡ãƒ¼ã‚¿å‡¦ç†å¤±æ•—")
                    if result.errors:
                        print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°ï¼ˆæœ€æ–°{ScraperConstants.ERROR_DISPLAY_LIMIT}ä»¶ï¼‰:")
                        for error in result.errors[:ScraperConstants.ERROR_DISPLAY_LIMIT]:
                            print(f"  - {error}")
                    return False

            except ValidationError as e:
                self._error_handler.handle_error(e, ErrorSeverity.MEDIUM, ErrorCategory.VALIDATION)
                print(f"âŒ {category}ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
                return False
            except Exception as e:
                self._error_handler.handle_error(e, ErrorSeverity.HIGH, ErrorCategory.PROCESSING)
                print(f"âŒ {category}ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                return False

    def get_processing_statistics(self) -> dict:
        """å‡¦ç†çµ±è¨ˆã‚’å–å¾— - Phase 2æ”¹å–„"""
        return {
            "performance_stats": self._performance_monitor.get_performance_stats(),
            "error_stats": self._error_handler.get_error_stats(),
            "system_health": self._performance_monitor.get_system_health(),
            "workflow_stats": self._workflow.get_processing_statistics() if hasattr(self._workflow, 'get_processing_statistics') else {}
        }

    def _display_processing_statistics(self, stats: dict) -> None:
        """å‡¦ç†çµ±è¨ˆã‚’è¡¨ç¤º"""
        print(f"\n{'='*60}")
        print("ğŸ“ˆ å‡¦ç†çµ±è¨ˆã‚µãƒãƒªãƒ¼")
        print(f"{'='*60}")

        # ã‚·ã‚¹ãƒ†ãƒ å¥å…¨æ€§
        health = stats.get('system_health', {})
        print(f"ğŸ¥ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: {health.get('status', 'unknown')}")

        if health.get('api_success_rate'):
            print(f"ğŸ“¡ APIæˆåŠŸç‡: {health['api_success_rate']:.1%}")

        if health.get('avg_response_time'):
            print(f"â±ï¸ å¹³å‡å¿œç­”æ™‚é–“: {health['avg_response_time']:.2f}ç§’")

        # ã‚¨ãƒ©ãƒ¼çµ±è¨ˆ
        error_stats = stats.get('error_stats', {})
        if error_stats.get('total_errors', 0) > 0:
            print(f"âŒ ç·ã‚¨ãƒ©ãƒ¼æ•°: {error_stats['total_errors']}")

            # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã‚¨ãƒ©ãƒ¼
            error_by_category = error_stats.get('errors_by_category', {})
            if error_by_category:
                print("ğŸ“‹ ã‚¨ãƒ©ãƒ¼ã‚«ãƒ†ã‚´ãƒªåˆ¥:")
                for category, count in error_by_category.items():
                    print(f"  - {category}: {count}ä»¶")

        print(f"{'='*60}")

def run_async_main(args) -> bool:
    """éåŒæœŸãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    async def _async_main():
        try:
            # ç’°å¢ƒãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            _load_environment_file(args.env_file)

            # è¨­å®šã¨ã‚³ãƒ³ãƒ†ãƒŠåˆæœŸåŒ–
            config = ScraperConfig.from_environment()
            container = create_container(config)
            cli = ScraperCLI(config, container)

            # ç’°å¢ƒæ¤œè¨¼
            if not cli.validate_environment():
                return False

            # éåŒæœŸå‡¦ç†å®Ÿè¡Œ
            return await cli.run_unified_processing_async(
                target=args.target,
                mode=args.mode,
                dry_run=args.dry_run,
                separate_location=not args.no_separate_location
            )

        except Exception as e:
            print(f"âŒ éåŒæœŸå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False

    # éåŒæœŸå®Ÿè¡Œ
    return asyncio.run(_async_main())

def _load_environment_file(env_file_path: Optional[str]) -> None:
    """ç’°å¢ƒãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ï¼ˆå…±é€šåŒ–ï¼‰"""
    if env_file_path:
        from shared.config import load_env_to_os
        load_env_to_os(env_file_path)

def _handle_config_check(args) -> None:
    """ç’°å¢ƒå¤‰æ•°è¨­å®šãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ"""
    from shared.config import validate_environment_setup, check_config_creation

    print("ğŸ” ç’°å¢ƒå¤‰æ•°è¨­å®šæ¤œè¨¼")
    print("=" * 60)

    # ç’°å¢ƒãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’OSã®ç’°å¢ƒå¤‰æ•°ã«èª­ã¿è¾¼ã¿
    _load_environment_file(args.env_file)

    # ç’°å¢ƒãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
    env_valid = validate_environment_setup(args.env_file)

    # è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆãƒ†ã‚¹ãƒˆ
    config_valid = check_config_creation()

    # çµæœå‡ºåŠ›
    overall_success = env_valid and config_valid
    print("\n" + "=" * 60)
    print("æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    print(f"ç’°å¢ƒãƒ•ã‚¡ã‚¤ãƒ«: {'âœ… VALID' if env_valid else 'âŒ INVALID'}")
    print(f"è¨­å®šã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ: {'âœ… VALID' if config_valid else 'âŒ INVALID'}")
    print(f"\nç·åˆåˆ¤å®š: {'âœ… æœ¬ç•ªç’°å¢ƒå¯¾å¿œå¯èƒ½' if overall_success else 'âŒ ä¿®æ­£ãŒå¿…è¦'}")

    sys.exit(0 if overall_success else 1)


def _handle_connection_test() -> None:
    """APIæ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    print("ğŸŒ APIæ¥ç¶šãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    try:
        # ç’°å¢ƒãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ config/.env ã‚’ä½¿ç”¨ï¼‰
        _load_environment_file(ScraperConstants.DEFAULT_ENV_FILE)

        # è¨­å®šèª­ã¿è¾¼ã¿
        config = ScraperConfig.from_environment()
        container = create_container(config)

        # Google Places APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
        print("\nğŸ“ Google Places APIæ¥ç¶šãƒ†ã‚¹ãƒˆ...")

        from infrastructure.external.places_api_adapter import PlacesAPIAdapter
        places_client = container.get(PlacesAPIAdapter)

        # ç°¡å˜ãªAPI ã‚­ãƒ¼æ¤œè¨¼ã‚’å®Ÿè¡Œ
        test_place_id = "ChIJN1t_tDeuEmsRUsoyG83frY4"  # æœ‰åãªå ´æ‰€ã®Place ID
        test_result = places_client.fetch_place_details(test_place_id)

        if test_result and test_result.get('id'):
            print("âœ… Google Places API: æ¥ç¶šæˆåŠŸ")
        else:
            print("âš ï¸ Google Places API: ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒç©ºã§ã™")

        # Google Sheets APIæ¥ç¶šãƒ†ã‚¹ãƒˆ
        print("\nğŸ“Š Google Sheets APIæ¥ç¶šãƒ†ã‚¹ãƒˆ...")

        # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®åŸºæœ¬æƒ…å ±ã‚’å–å¾—ã—ã¦ãƒ†ã‚¹ãƒˆ
        try:
            from infrastructure.storage.sheets_storage_adapter import SheetsStorageAdapter
            sheets_client = container.get(SheetsStorageAdapter)

            # å®Ÿéš›ã«ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®å­˜åœ¨ç¢ºèªã‚’å®Ÿè¡Œ
            if config.google_api.spreadsheet_id:
                sheets_info = sheets_client.test_connection()
                if sheets_info:
                    print("âœ… Google Sheets API: æ¥ç¶šæˆåŠŸ")
                    print(f"   ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ: {sheets_info.get('title', 'Unknown')}")
                else:
                    print("âš ï¸ Google Sheets API: ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã¾ã›ã‚“")
            else:
                print("âš ï¸ Google Sheets API: ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDãŒæœªè¨­å®š")
        except Exception as sheets_error:
            print(f"âŒ Google Sheets API: æ¥ç¶šå¤±æ•— - {sheets_error}")

        print("\nâœ… æ¥ç¶šãƒ†ã‚¹ãƒˆå®Œäº†")

    except Exception as e:
        print(f"âŒ æ¥ç¶šãƒ†ã‚¹ãƒˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        sys.exit(1)

    sys.exit(0)


def _handle_separate_only(args) -> None:
    """ãƒ‡ãƒ¼ã‚¿åˆ†é›¢ã®ã¿å®Ÿè¡Œ"""
    print("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿åˆ†é›¢å‡¦ç†")
    print("=" * 60)

    try:
        # ç’°å¢ƒãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
        _load_environment_file(args.env_file)

        config = ScraperConfig.from_environment()
        container = create_container(config)

        from core.processors.data_processor import DataProcessor
        processor = container.get(DataProcessor)

        # æ—¢å­˜ã®çµæœãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã«ã®ã¿åˆ†é›¢å®Ÿè¡Œ
        if processor.results:
            print(f"ğŸ“Š {len(processor.results)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é›¢ä¸­...")
            sado_results, outside_results = processor.separate_sado_data(processor.results)

            print("âœ… åˆ†é›¢å®Œäº†:")
            print(f"   ä½æ¸¡å¸‚å†…: {len(sado_results)}ä»¶")
            print(f"   ä½æ¸¡å¸‚å¤–: {len(outside_results)}ä»¶")
        else:
            print("âš ï¸ åˆ†é›¢å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            print("   ã¾ãšé€šå¸¸ã®å‡¦ç†ã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ãã ã•ã„")

    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿åˆ†é›¢å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)

    sys.exit(0)


def _create_argument_parser():
    """å¼•æ•°ãƒ‘ãƒ¼ã‚µãƒ¼ã‚’ä½œæˆ"""
    parser = argparse.ArgumentParser(description='ä½æ¸¡é£²é£Ÿåº—ãƒãƒƒãƒ— - æ–°ã—ã„APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆçµ±åˆå‡¦ç† (Phase 2æ”¹å–„ç‰ˆ)')
    parser.add_argument('--mode', choices=['quick', 'standard', 'comprehensive'],
                       default='standard', help='å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰')
    parser.add_argument('--target', choices=['all', 'restaurants', 'parkings', 'toilets'],
                       default='all', help='å‡¦ç†å¯¾è±¡')
    parser.add_argument('--dry-run', action='store_true', help='ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆè¦‹ç©ã‚‚ã‚Šã®ã¿ï¼‰')
    parser.add_argument('--no-separate', action='store_true', help='ä½æ¸¡å¸‚å†…ãƒ»å¸‚å¤–åˆ†é›¢ã‚’ç„¡åŠ¹åŒ–')
    parser.add_argument('--separate-only', action='store_true', help='ãƒ‡ãƒ¼ã‚¿åˆ†é›¢ã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--config-check', action='store_true', help='ç’°å¢ƒå¤‰æ•°è¨­å®šã®æ¤œè¨¼ã®ã¿å®Ÿè¡Œ')
    parser.add_argument('--test-connections', action='store_true', help='APIæ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ')
    parser.add_argument('--env-file', type=str, default=ScraperConstants.DEFAULT_ENV_FILE,
                       help='ç’°å¢ƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆ.env.productionç­‰ï¼‰')
    # Phase 2æ”¹å–„: éåŒæœŸå‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument('--async-mode', action='store_true', help='éåŒæœŸå‡¦ç†ã‚’æœ‰åŠ¹åŒ–ï¼ˆPhase 2æ”¹å–„ï¼‰')
    parser.add_argument('--sync', action='store_true', help='åŒæœŸå‡¦ç†ã‚’å¼·åˆ¶ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰')
    return parser


def _run_main_processing(args) -> None:
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†ã®å®Ÿè¡Œ"""
    try:
        # è¨­å®šã¨ãƒ­ã‚¬ãƒ¼ã®åˆæœŸåŒ–
        config, logger = _setup_config_and_logging(args)

        # ã‚µãƒ¼ãƒ“ã‚¹ã¨CLIã®åˆæœŸåŒ–
        _, cli = _setup_services(config)

        # ç’°å¢ƒæ¤œè¨¼
        if not _validate_environment(cli, logger):
            return

        # çµ±åˆå‡¦ç†å®Ÿè¡Œ
        _execute_processing(cli, args, logger)

    except ConfigurationError as e:
        _handle_configuration_error(e)
    except Exception as e:
        _handle_unexpected_error(e)


def _setup_config_and_logging(args):
    """è¨­å®šã¨ãƒ­ã‚®ãƒ³ã‚°ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
    print("âš™ï¸ è¨­å®šèª­ã¿è¾¼ã¿ä¸­...")

    # ç’°å¢ƒãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
    _load_environment_file(args.env_file)

    config = ScraperConfig.from_environment()

    logging_config = LoggingConfig(
        level='DEBUG' if config.debug else 'INFO',
        output_file='logs/scraper.log'
    )
    configure_logging(logging_config)
    logger = get_logger(__name__)

    logger.info("ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼é–‹å§‹",
               target=args.target,
               mode=args.mode,
               dry_run=args.dry_run)

    config_summary = config.get_summary()
    logger.info("è¨­å®šã‚µãƒãƒªãƒ¼", **config_summary)

    return config, logger


def _setup_services(config):
    """ã‚µãƒ¼ãƒ“ã‚¹ã¨CLIã®åˆæœŸåŒ–"""
    print("ğŸ”§ ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–ä¸­...")
    container = create_container(config)
    cli = ScraperCLI(config, container)
    return container, cli


def _validate_environment(cli, logger) -> bool:
    """ç’°å¢ƒå¤‰æ•°ã®æ¤œè¨¼"""
    print("ğŸ” ç’°å¢ƒå¤‰æ•°ã®æ¤œè¨¼ã‚’é–‹å§‹...")
    if not cli.validate_environment():
        logger.error("ç’°å¢ƒå¤‰æ•°ã®æ¤œè¨¼ã«å¤±æ•—")
        print("âŒ ç’°å¢ƒå¤‰æ•°ã®æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return False
    return True


def _execute_processing(cli, args, logger) -> None:
    """çµ±åˆå‡¦ç†ã®å®Ÿè¡Œ"""
    logger.info("çµ±åˆå‡¦ç†é–‹å§‹")
    success = cli.run_unified_processing(
        target=args.target,
        mode=args.mode,
        dry_run=args.dry_run,
        separate_location=not args.no_separate
    )

    if success:
        logger.info("å‡¦ç†å®Œäº†", success=True)
        print("âœ… å…¨ä½“å‡¦ç†å®Œäº†")
    else:
        logger.error("å‡¦ç†å¤±æ•—", success=False)
        print("âŒ å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")


def _handle_configuration_error(e) -> None:
    """è¨­å®šã‚¨ãƒ©ãƒ¼ã®å‡¦ç†"""
    print(f"âŒ è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
    if hasattr(e, 'missing_keys') and e.missing_keys:
        print("ä¸è¶³ã—ã¦ã„ã‚‹ç’°å¢ƒå¤‰æ•°:")
        for key in e.missing_keys:
            print(f"  - {key}")
    sys.exit(1)


def _handle_unexpected_error(e) -> None:
    """äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†"""
    print(f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
    sys.exit(1)


def _show_header() -> None:
    """ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ã®è¡¨ç¤º"""
    print("ğŸš€ ä½æ¸¡é£²é£Ÿåº—ãƒãƒƒãƒ— - æ–°ã—ã„APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆçµ±åˆå‡¦ç†å®Ÿè¡Œ")
    print("=" * 60)
    print(f"ğŸ• é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("ğŸ“¦ ãƒãƒ¼ã‚¸ãƒ§ãƒ³: v2.2 (New API Client)")
    print("-" * 60)


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç† - Phase 2æ”¹å–„ç‰ˆ"""
    parser = _create_argument_parser()
    args = parser.parse_args()

    # ç‰¹æ®Šã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å‡¦ç†
    if args.config_check:
        _handle_config_check(args)

    if args.test_connections:
        _handle_connection_test()

    if args.separate_only:
        _handle_separate_only(args)

    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
    _show_header()

    # Phase 2æ”¹å–„: éåŒæœŸ/åŒæœŸå‡¦ç†ã®é¸æŠ
    if hasattr(args, 'async_mode') and args.async_mode and not args.sync:
        print("ğŸš€ éåŒæœŸå‡¦ç†ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œä¸­...")
        success = run_async_main(args)
        sys.exit(0 if success else 1)
    else:
        # å¾“æ¥ã®åŒæœŸå‡¦ç†
        if hasattr(args, 'sync') and args.sync:
            print("ğŸ”„ åŒæœŸå‡¦ç†ãƒ¢ãƒ¼ãƒ‰ï¼ˆå¼·åˆ¶ï¼‰ã§å®Ÿè¡Œä¸­...")
        _run_main_processing(args)

if __name__ == "__main__":
    main()
