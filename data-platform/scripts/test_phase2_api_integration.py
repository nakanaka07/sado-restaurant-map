#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 2 APIçµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

æ—¢å­˜Places API Adapterã¨Phase 3-Fullåˆ†æ•£ã‚¿ã‚¹ã‚¯ã‚·ã‚¹ãƒ†ãƒ ã®çµ±åˆãƒ†ã‚¹ãƒˆ
"""

import sys
import os
import asyncio
import logging
import json
from datetime import datetime
from typing import List, Dict, Any

# ãƒ‘ã‚¹è¨­å®š
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from shared.api_integration import create_api_integration, APIIntegrationConfig
from shared.cache_service import CacheService
from shared.distributed_tasks import BatchTaskConfig, DistributedTaskProcessor
from shared.distributed_tasks import process_places_batch, aggregate_batch_results
from shared.exceptions import APIError, ProcessingError


class Phase2APIIntegrationTester:
    """Phase 2 APIçµ±åˆãƒ†ã‚¹ã‚¿ãƒ¼"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.setup_logging()
        self.test_results = {}
        self.api_key = os.getenv('PLACES_API_KEY')

    def setup_logging(self):
        """ãƒ­ã‚°è¨­å®š"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )

    async def test_api_integration_basic(self) -> bool:
        """åŸºæœ¬çš„ãªAPIçµ±åˆãƒ†ã‚¹ãƒˆ"""
        self.logger.info("--- APIçµ±åˆåŸºæœ¬ãƒ†ã‚¹ãƒˆ ---")

        try:
            if not self.api_key:
                self.logger.warning("âš ï¸ PLACES_API_KEYæœªè¨­å®š - ãƒ¢ãƒƒã‚¯ãƒ†ã‚¹ãƒˆã®ã¿å®Ÿè¡Œ")
                return await self._test_mock_integration()

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
            from shared.cache_service import CacheConfig

            cache_config = CacheConfig(redis_nodes=[])
            cache_service = CacheService(cache_config)

            # APIçµ±åˆã‚µãƒ¼ãƒ“ã‚¹ä½œæˆ
            api_integration = create_api_integration(
                api_key=self.api_key,
                cache_service=cache_service,
                batch_size=5,
                request_delay=1.0
            )

            self.logger.info("âœ… APIçµ±åˆã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–: OK")

            # ãƒ†ã‚¹ãƒˆç”¨Place IDsï¼ˆå®Ÿéš›ã®Google Places IDsï¼‰
            test_place_ids = [
                "ChIJN1t_tDeuEmsRUsoyG83frY4",  # Google Sydney
                "ChIJrTLr-GyuEmsRBfy61i59si0",  # Sydney Opera House
                "ChIJ_____9FXXkARxxxxxxxxxxxxx"   # ç„¡åŠ¹ãªIDï¼ˆã‚¨ãƒ©ãƒ¼ãƒ†ã‚¹ãƒˆç”¨ï¼‰
            ]

            # å˜ä¸€Placeå–å¾—ãƒ†ã‚¹ãƒˆ
            place_data = await api_integration.fetch_place_details_with_cache(test_place_ids[0])
            if place_data:
                self.logger.info(f"âœ… å˜ä¸€Placeå–å¾—: OK ({place_data.display_name})")
                self.test_results['single_place_fetch'] = True
            else:
                self.logger.warning("âš ï¸ å˜ä¸€Placeå–å¾—: ãƒ‡ãƒ¼ã‚¿ãªã—")
                self.test_results['single_place_fetch'] = False

            # ãƒãƒƒãƒå–å¾—ãƒ†ã‚¹ãƒˆ
            results, errors, stats = await api_integration.batch_fetch_places(test_place_ids)

            self.logger.info(f"âœ… ãƒãƒƒãƒå–å¾—å®Œäº†: {len(results)}ä»¶æˆåŠŸ, {len(errors)}ä»¶ã‚¨ãƒ©ãƒ¼")
            self.logger.info(f"   ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡: {stats.get('cache_hit_rate', 0):.1f}%")
            self.logger.info(f"   å‡¦ç†æ™‚é–“: {stats.get('processing_time', 0):.2f}ç§’")

            self.test_results['batch_fetch'] = len(results) > 0
            self.test_results['api_integration_stats'] = stats

            return len(results) > 0

        except Exception as e:
            self.logger.error(f"âŒ APIçµ±åˆåŸºæœ¬ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.test_results['api_integration_basic'] = False
            return False

    async def _test_mock_integration(self) -> bool:
        """ãƒ¢ãƒƒã‚¯çµ±åˆãƒ†ã‚¹ãƒˆ"""
        try:
            # ãƒ¢ãƒƒã‚¯ç”¨ã®APIçµ±åˆï¼ˆAPIã‚­ãƒ¼ãªã—ï¼‰
            from shared.cache_service import CacheConfig

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§CacheConfigã‚’ä½œæˆ
            cache_config = CacheConfig(redis_nodes=[])
            cache_service = CacheService(cache_config)

            # ãƒ†ã‚¹ãƒˆç”¨Place IDs
            test_place_ids = ["test_place_1", "test_place_2", "test_place_3"]

            self.logger.info("âœ… ãƒ¢ãƒƒã‚¯APIçµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
            self.test_results['mock_integration'] = True

            return True

        except Exception as e:
            self.logger.error(f"âŒ ãƒ¢ãƒƒã‚¯çµ±åˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def test_distributed_tasks_with_api(self) -> bool:
        """åˆ†æ•£ã‚¿ã‚¹ã‚¯ã¨APIçµ±åˆãƒ†ã‚¹ãƒˆ"""
        self.logger.info("--- åˆ†æ•£ã‚¿ã‚¹ã‚¯ãƒ»APIçµ±åˆãƒ†ã‚¹ãƒˆ ---")

        try:
            # ãƒ†ã‚¹ãƒˆç”¨è¨­å®š
            config = BatchTaskConfig(
                batch_size=5,
                use_real_api=bool(self.api_key),  # APIã‚­ãƒ¼ãŒã‚ã‚Œã°å®Ÿéš›ã®APIã‚’ä½¿ç”¨
                use_cache=True
            )

            # ãƒ†ã‚¹ãƒˆç”¨Place IDs
            if self.api_key:
                # å®Ÿéš›ã®Place IDsï¼ˆå°‘æ•°ã§ãƒ†ã‚¹ãƒˆï¼‰
                test_place_ids = [
                    "ChIJN1t_tDeuEmsRUsoyG83frY4",  # Google Sydney
                    "ChIJrTLr-GyuEmsRBfy61i59si0",  # Sydney Opera House
                ]
            else:
                # ãƒ¢ãƒƒã‚¯Place IDs
                test_place_ids = ["test_place_1", "test_place_2", "test_place_3", "test_place_4"]

            # åˆ†æ•£ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ
            task_result = process_places_batch.apply(
                args=[test_place_ids, config.__dict__]
            )

            result = task_result.get()

            self.logger.info(f"âœ… åˆ†æ•£ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ: OK")
            self.logger.info(f"   å‡¦ç†æ¸ˆã¿: {result.get('processed', 0)}ä»¶")
            self.logger.info(f"   APIå‘¼ã³å‡ºã—: {result.get('api_calls', 0)}ä»¶")
            self.logger.info(f"   ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {result.get('cache_hits', 0)}ä»¶")
            self.logger.info(f"   ã‚¨ãƒ©ãƒ¼: {result.get('errors', 0)}ä»¶")
            self.logger.info(f"   APIãƒ¢ãƒ¼ãƒ‰: {result.get('api_mode', 'unknown')}")

            self.test_results['distributed_task_with_api'] = result.get('processed', 0) > 0
            self.test_results['distributed_task_result'] = result

            return result.get('processed', 0) > 0

        except Exception as e:
            self.logger.error(f"âŒ åˆ†æ•£ã‚¿ã‚¹ã‚¯ãƒ»APIçµ±åˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.test_results['distributed_task_with_api'] = False
            return False

    def test_batch_aggregation(self) -> bool:
        """ãƒãƒƒãƒçµæœé›†ç´„ãƒ†ã‚¹ãƒˆ"""
        self.logger.info("--- ãƒãƒƒãƒçµæœé›†ç´„ãƒ†ã‚¹ãƒˆ ---")

        try:
            # ãƒ¢ãƒƒã‚¯ãƒãƒƒãƒçµæœ
            batch_results = [
                {
                    "status": "success",
                    "processed": 3,
                    "total_requested": 3,
                    "cache_hits": 1,
                    "api_calls": 2,
                    "results": [
                        {"place_id": "test_1", "name": "åº—èˆ—1", "rating": 4.1},
                        {"place_id": "test_2", "name": "åº—èˆ—2", "rating": 4.2},
                        {"place_id": "test_3", "name": "åº—èˆ—3", "rating": 4.3}
                    ]
                },
                {
                    "status": "success",
                    "processed": 2,
                    "total_requested": 2,
                    "cache_hits": 0,
                    "api_calls": 2,
                    "results": [
                        {"place_id": "test_4", "name": "åº—èˆ—4", "rating": 4.4},
                        {"place_id": "test_5", "name": "åº—èˆ—5", "rating": 4.5}
                    ]
                }
            ]

            # é›†ç´„å®Ÿè¡Œ
            aggregation_result = aggregate_batch_results.apply(
                args=[batch_results]
            )

            result = aggregation_result.get()

            self.logger.info(f"âœ… ãƒãƒƒãƒçµæœé›†ç´„: OK")
            self.logger.info(f"   ç·å‡¦ç†æ•°: {result.get('total_processed', 0)}ä»¶")
            self.logger.info(f"   æˆåŠŸç‡: {result.get('success_rate', 0):.1f}%")
            self.logger.info(f"   ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡: {result.get('cache_hit_rate', 0):.1f}%")

            self.test_results['batch_aggregation'] = result.get('total_processed', 0) > 0
            self.test_results['aggregation_result'] = result

            return result.get('total_processed', 0) > 0

        except Exception as e:
            self.logger.error(f"âŒ ãƒãƒƒãƒçµæœé›†ç´„ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.test_results['batch_aggregation'] = False
            return False

    async def run_all_tests(self) -> Dict[str, Any]:
        """å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        self.logger.info("=== Phase 2 APIçµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹ ===")
        start_time = datetime.now()

        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        tests = [
            ("APIçµ±åˆåŸºæœ¬", self.test_api_integration_basic()),
            ("åˆ†æ•£ã‚¿ã‚¹ã‚¯ãƒ»APIçµ±åˆ", self.test_distributed_tasks_with_api),
            ("ãƒãƒƒãƒçµæœé›†ç´„", self.test_batch_aggregation)
        ]

        passed = 0
        total = len(tests)

        for test_name, test_func in tests:
            try:
                if asyncio.iscoroutine(test_func):
                    result = await test_func
                else:
                    result = test_func()

                if result:
                    passed += 1
                    self.logger.info(f"âœ… {test_name}: æˆåŠŸ")
                else:
                    self.logger.warning(f"âš ï¸ {test_name}: å¤±æ•—")

            except Exception as e:
                self.logger.error(f"âŒ {test_name}: ã‚¨ãƒ©ãƒ¼ - {e}")

        # çµæœã‚µãƒãƒªãƒ¼
        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()
        success_rate = (passed / total) * 100

        summary = {
            "total_tests": total,
            "passed_tests": passed,
            "success_rate": success_rate,
            "execution_time": execution_time,
            "timestamp": end_time.isoformat(),
            "api_key_available": bool(self.api_key),
            "test_results": self.test_results
        }

        self.logger.info(f"=== Phase 2 APIçµ±åˆãƒ†ã‚¹ãƒˆå®Œäº† ({execution_time:.2f}ç§’) ===")
        self.logger.info(f"æˆåŠŸç‡: {success_rate:.1f}% ({passed}/{total})")

        if self.api_key:
            self.logger.info("ğŸ”‘ å®Ÿéš›ã®APIçµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        else:
            self.logger.info("ğŸ”§ ãƒ¢ãƒƒã‚¯çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")

        # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        result_file = f"phase2_api_integration_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)

        self.logger.info(f"ãƒ†ã‚¹ãƒˆçµæœã‚’ {result_file} ã«ä¿å­˜ã—ã¾ã—ãŸ")

        return summary


async def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    tester = Phase2APIIntegrationTester()

    try:
        results = await tester.run_all_tests()

        if results['success_rate'] >= 70:
            print(f"\nğŸ‰ Phase 2 APIçµ±åˆ: æˆåŠŸ ({results['success_rate']:.1f}%)")
            return 0
        else:
            print(f"\nâš ï¸ Phase 2 APIçµ±åˆ: è¦æ”¹å–„ ({results['success_rate']:.1f}%)")
            return 1

    except Exception as e:
        print(f"\nâŒ Phase 2 APIçµ±åˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
