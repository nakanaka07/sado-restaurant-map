#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–°ã—ã„APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå¯¾å¿œç‰ˆ - çµ±åˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Places API (New) v1ã‚’ä½¿ç”¨ã—ãŸæœ€æ–°ç‰ˆå®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ 
Clean Architectureæº–æ‹ ãƒ»ä¾å­˜æ€§æ³¨å…¥å¯¾å¿œç‰ˆ
"""

import argparse
import os
import sys
import time
from datetime import datetime
from pathlib import Path

# ãƒ‘ã‚¹è¨­å®š
current_dir = Path(__file__).parent
scraper_root = current_dir.parent.parent
sys.path.insert(0, str(scraper_root))

# æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¯¾å¿œã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from shared.config.settings import ScraperConfig
from shared.container import DIContainer
from shared.logging.logger import get_logger, setup_logging
from shared.exceptions import ConfigurationError, ValidationError
from application.workflows.data_processing_workflow import DataProcessingWorkflow
from shared.types.core_types import CategoryType

class ScraperCLI:
    """æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¯¾å¿œCLIå®Ÿè¡Œã‚¯ãƒ©ã‚¹"""

    def __init__(self, config: ScraperConfig, container: DIContainer):
        """CLIåˆæœŸåŒ–"""
        self._config = config
        self._container = container
        self._logger = get_logger(__name__)

        # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’å–å¾—
        self._workflow = self._container.get(DataProcessingWorkflow)

        self.data_files = {
            'restaurants': 'data/urls/restaurants_merged.txt',
            'parkings': 'data/urls/parkings_merged.txt',
            'toilets': 'data/urls/toilets_merged.txt'
        }

    def validate_environment(self) -> bool:
        """ç’°å¢ƒè¨­å®šã®æ¤œè¨¼"""
        try:
            # API ã‚­ãƒ¼ã®æ¤œè¨¼
            if not self._config.google_api.places_api_key:
                self._logger.error("Places API ã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False

            # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDã®æ¤œè¨¼
            if not self._config.google_api.spreadsheet_id:
                self._logger.error("ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆIDãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                return False

            # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
            if not Path(self._config.google_api.service_account_path).exists():
                self._logger.error("ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", 
                                 path=self._config.google_api.service_account_path)
                return False

            self._logger.info("ç’°å¢ƒè¨­å®šæ¤œè¨¼å®Œäº†")
            return True

        except Exception as e:
            self._logger.error("ç’°å¢ƒè¨­å®šæ¤œè¨¼ã‚¨ãƒ©ãƒ¼", error=str(e))
            return False

    def validate_file(self, file_path: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª"""
        return self._workflow.validate_file(file_path)

    def count_queries(self, file_path: str) -> int:
        """ã‚¯ã‚¨ãƒªæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        return self._workflow.count_queries(file_path)

    def show_execution_plan(self, target: str, mode: str):
        """å®Ÿè¡Œè¨ˆç”»ã‚’è¡¨ç¤º"""
        print(f"ğŸ“Š å®Ÿè¡Œè¨ˆç”»")
        print(f"   ãƒ¢ãƒ¼ãƒ‰: {self.get_mode_description(mode)}")
        print(f"   å¯¾è±¡ãƒ‡ãƒ¼ã‚¿: {target}")

        total_queries = 0
        file_details = []

        if target == 'all':
            for category, file_path in self.data_files.items():
                if self.validate_file(file_path):
                    count = self.count_queries(file_path)
                    total_queries += count
                    file_details.append(f"   ğŸ“„ {category}: {count}ä»¶")
        else:
            if target in self.data_files:
                file_path = self.data_files[target]
                if self.validate_file(file_path):
                    count = self.count_queries(file_path)
                    total_queries += count
                    file_details.append(f"   ğŸ“„ {target}: {count}ä»¶")

        print(f"   ç·ã‚¯ã‚¨ãƒªæ•°: {total_queries}ä»¶")
        print(f"   æ¨å®šã‚³ã‚¹ãƒˆ: ${total_queries * 0.017:.3f} USD")
        print(f"   æ¨å®šå®Ÿè¡Œæ™‚é–“: {total_queries * 1.2 / 60:.1f} åˆ†")

        print(f"\nğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«è©³ç´°:")
        for detail in file_details:
            print(detail)

        return total_queries

    def get_mode_description(self, mode: str) -> str:
        """ãƒ¢ãƒ¼ãƒ‰èª¬æ˜ã‚’å–å¾—"""
        descriptions = {
            'quick': 'é«˜é€Ÿãƒ¢ãƒ¼ãƒ‰ï¼ˆCID URLã®ã¿å‡¦ç†ï¼‰',
            'standard': 'æ¨™æº–ãƒ¢ãƒ¼ãƒ‰ï¼ˆCID URL + é«˜ç²¾åº¦åº—èˆ—åï¼‰',
            'comprehensive': 'åŒ…æ‹¬ãƒ¢ãƒ¼ãƒ‰ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ + è©³ç´°æ¤œè¨¼ï¼‰'
        }
        return descriptions.get(mode, mode)

    def run_category(self, category: str, mode: str, dry_run: bool = False, separate_location: bool = True) -> bool:
        """ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®å‡¦ç†å®Ÿè¡Œ"""
        file_path = self.data_files.get(category)
        if not file_path or not self.validate_file(file_path):
            print(f"âŒ {category}ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã‹ç©ºã§ã™: {file_path}")
            return False

        if dry_run:
            print(f"ğŸ“‹ {category}ãƒ‡ãƒ¼ã‚¿: ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Œäº†")
            return True

        print(f"\nğŸ”„ {category}ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­...")

        try:
            # ãƒ—ãƒ­ã‚»ãƒƒã‚µãƒ¼åˆæœŸåŒ–
            processor = NewUnifiedProcessor()

            # ã‚¯ã‚¨ãƒªè§£æ
            queries = processor.parse_query_file(file_path)
            if not queries:
                print(f"âŒ {category}ã‚¯ã‚¨ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return False

            # å‡¦ç†å®Ÿè¡Œ
            results = processor.process_all_queries(queries)

            # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜
            if results:
                success = processor.save_to_spreadsheet(category, separate_location)
                if success:
                    print(f"âœ… {category}ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Œäº†: {len(results)}ä»¶")
                    return True
                else:
                    print(f"âŒ {category}ãƒ‡ãƒ¼ã‚¿ä¿å­˜å¤±æ•—")
                    return False
            else:
                print(f"âŒ {category}ãƒ‡ãƒ¼ã‚¿: å‡¦ç†çµæœãªã—")
                return False

        except Exception as e:
            print(f"âŒ {category}ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def run_unified_processing(self, target: str = 'all', mode: str = 'standard',
                             dry_run: bool = False, separate_location: bool = True) -> bool:
        """çµ±åˆå‡¦ç†å®Ÿè¡Œ"""

        # å®Ÿè¡Œè¨ˆç”»è¡¨ç¤º
        total_queries = self.show_execution_plan(target, mode)

        if total_queries == 0:
            print("âŒ å‡¦ç†å¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False

        if dry_run:
            print(f"\n{'='*60}")
            print(f"ğŸ‰ å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
            print(f"ğŸ“ ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Œäº†ï¼ˆå®Ÿéš›ã®å‡¦ç†ã¯è¡Œã„ã¾ã›ã‚“ã§ã—ãŸï¼‰")
            print(f"ğŸ• çµ‚äº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            return True

        # å®Ÿè¡Œç¢ºèª
        if not dry_run:
            confirmation = input("\nå®Ÿè¡Œã‚’ç¶šã‘ã¾ã™ã‹ï¼Ÿ (y/N): ")
            if confirmation.lower() != 'y':
                print("å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã—ãŸ")
                return False

        # å‡¦ç†å®Ÿè¡Œ
        success_count = 0
        total_count = 0

        if target == 'all':
            categories = list(self.data_files.keys())
        else:
            categories = [target] if target in self.data_files else []

        for category in categories:
            total_count += 1
            if self.run_category(category, mode, dry_run, separate_location):
                success_count += 1

        # çµæœè¡¨ç¤º
        print(f"\n{'='*60}")
        if success_count == total_count:
            print(f"ğŸ‰ å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        else:
            print(f"âš ï¸ å‡¦ç†ãŒéƒ¨åˆ†çš„ã«å®Œäº†ã—ã¾ã—ãŸ")

        print(f"ğŸ“Š æˆåŠŸ: {success_count}/{total_count} ã‚«ãƒ†ã‚´ãƒª")
        print(f"ğŸ• çµ‚äº†æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        return success_count > 0

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description='ä½æ¸¡é£²é£Ÿåº—ãƒãƒƒãƒ— - æ–°ã—ã„APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆçµ±åˆå‡¦ç†')
    parser.add_argument('--mode', choices=['quick', 'standard', 'comprehensive'],
                       default='standard', help='å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰')
    parser.add_argument('--target', choices=['all', 'restaurants', 'parkings', 'toilets'],
                       default='all', help='å‡¦ç†å¯¾è±¡')
    parser.add_argument('--dry-run', action='store_true', help='ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆè¦‹ç©ã‚‚ã‚Šã®ã¿ï¼‰')
    parser.add_argument('--no-separate', action='store_true', help='ä½æ¸¡å¸‚å†…ãƒ»å¸‚å¤–åˆ†é›¢ã‚’ç„¡åŠ¹åŒ–')
    parser.add_argument('--separate-only', action='store_true', help='ãƒ‡ãƒ¼ã‚¿åˆ†é›¢ã®ã¿å®Ÿè¡Œ')

    args = parser.parse_args()

    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
    print("ğŸš€ ä½æ¸¡é£²é£Ÿåº—ãƒãƒƒãƒ— - æ–°ã—ã„APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆçµ±åˆå‡¦ç†å®Ÿè¡Œ")
    print("=" * 60)
    print(f"ğŸ• é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“¦ ãƒãƒ¼ã‚¸ãƒ§ãƒ³: v2.2 (New API Client)")
    print("-" * 60)

    # ç’°å¢ƒå¤‰æ•°æ¤œè¨¼
    print("ğŸ” ç’°å¢ƒå¤‰æ•°ã®æ¤œè¨¼ã‚’é–‹å§‹...")
    if not validate_environment():
        print("âŒ ç’°å¢ƒå¤‰æ•°ã®æ¤œè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return

    # çµ±åˆå‡¦ç†å®Ÿè¡Œ
    runner = NewUnifiedRunner()

    success = runner.run_unified_processing(
        target=args.target,
        mode=args.mode,
        dry_run=args.dry_run,
        separate_location=not args.no_separate
    )

    if success:
        print("âœ… å…¨ä½“å‡¦ç†å®Œäº†")
    else:
        print("âŒ å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")

if __name__ == "__main__":
    main()
