# optimized_places_data_updater.py
import requests
import gspread
import time
import os
import json
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# --- è¨­å®šé …ç›® ---
SCRIPT_DIR = os.path.dirname(os.path.realpath(__file__))
SERVICE_ACCOUNT_FILE_PATH = os.environ.get('GOOGLE_SERVICE_ACCOUNT_PATH', 
                                           os.path.join(SCRIPT_DIR, 'your-service-account-key.json'))
SPREADSHEET_ID = os.environ.get('SPREADSHEET_ID')
PLACES_API_KEY = os.environ.get('PLACES_API_KEY')

# APIãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“ã®å¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰- ç’°å¢ƒå¤‰æ•°ã§èª¿æ•´å¯èƒ½
API_REQUEST_DELAY = float(os.environ.get('API_DELAY', '1'))
SHEETS_API_DELAY = 1.5

# æ›´æ–°å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã®æŒ‡å®šï¼ˆã‚³ã‚¹ãƒˆæœ€é©åŒ–ï¼‰
TARGET_DATA = os.environ.get('TARGET_DATA', 'all')  # 'all', 'restaurants', 'parkings', 'toilets'

# ä½æ¸¡å³¶ã®å¢ƒç•Œãƒœãƒƒã‚¯ã‚¹
SADO_BOUNDS = {
    "north": 38.4,
    "south": 37.7,
    "east": 138.6,
    "west": 138.0
}

# ä½æ¸¡ã®åœ°åŒºåˆ†é¡
SADO_DISTRICTS = {
    'ä¸¡æ´¥åœ°åŒº': ['ä¸¡æ´¥', 'æ²³å´', 'ç§‹æ´¥', 'æ¢…æ´¥', 'æ¹Š', 'åŸé»’', 'åŒ—ç”°é‡æµ¦'],
    'ç›¸å·åœ°åŒº': ['ç›¸å·', 'æˆ¸ä¸­', 'åŒ—ç«‹å³¶', 'é”è€…', 'å…¥å·', 'åŒ—ç‰‡è¾º', 'é–¢'],
    'ä½å’Œç”°åœ°åŒº': ['ä½å’Œç”°', 'æ²¢æ ¹', 'çªªç”°', 'ä¸­åŸ', 'æ²³åŸç”°'],
    'é‡‘äº•åœ°åŒº': ['é‡‘äº•', 'åƒç¨®', 'å‰äº•', 'ä¸‹æ–°ç©‚', 'æ³‰', 'ä¸­èˆˆ'],
    'æ–°ç©‚åœ°åŒº': ['æ–°ç©‚', 'å¤§é‡', 'ä¸‹æ–°ç©‚', 'èˆŸä¸‹', 'çš†å·'],
    'ç•‘é‡åœ°åŒº': ['ç•‘é‡', 'å®®å·', 'æ —é‡æ±Ÿ', 'ç›®é»’ç”º', 'ä¸‰å®®', 'æ¾ãƒ¶å´'],
    'çœŸé‡åœ°åŒº': ['çœŸé‡', 'è±Šç”°', 'å››æ—¥ç”º', 'å‰å²¡', 'å¤§å°'],
    'å°æœ¨åœ°åŒº': ['å°æœ¨', 'å®¿æ ¹æœ¨', 'æ·±æµ¦', 'ç”°é‡æµ¦', 'å¼·æ¸…æ°´'],
    'ç¾½èŒ‚åœ°åŒº': ['ç¾½èŒ‚', 'å¤§çŸ³', 'ç¾½èŒ‚æœ¬éƒ·', 'ç¾½èŒ‚ä¸‰ç€¬', 'äº€è„‡'],
    'èµ¤æ³Šåœ°åŒº': ['èµ¤æ³Š', 'å¾³å’Œ', 'æŸ³æ²¢', 'å¤šç”°', 'èšå ´']
}

# ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®åŸºæœ¬ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
BASE_FIELDS = [
    "places.id",
    "places.shortFormattedAddress", 
    "places.location",
    "places.displayName",
    "places.primaryType",
    "places.primaryTypeDisplayName",
    "places.googleMapsLinks"
]

# é£²é£Ÿåº—ç”¨ã®è¿½åŠ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
RESTAURANT_ADDITIONAL_FIELDS = [
    "places.regularOpeningHours",
    "places.nationalPhoneNumber",
    "places.rating",
    "places.userRatingCount"
]

# ã‚«ãƒ†ã‚´ãƒªè¨­å®š
CATEGORIES = {
    "é£²é£Ÿåº—": {
        "worksheet": "é£²é£Ÿåº—",
        "fields": BASE_FIELDS + RESTAURANT_ADDITIONAL_FIELDS,
        "included_types": ["restaurant", "meal_takeaway", "cafe", "bar", "bakery"],
        "search_terms": ["ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³", "é£Ÿå ‚", "ã‚«ãƒ•ã‚§", "å±…é…’å±‹"]
    },
    "é§è»Šå ´": {
        "worksheet": "é§è»Šå ´", 
        "fields": BASE_FIELDS,
        "included_types": ["parking"],
        "search_terms": ["é§è»Šå ´", "ãƒ‘ãƒ¼ã‚­ãƒ³ã‚°", "parking"]
    },
    "å…¬è¡†ãƒˆã‚¤ãƒ¬": {
        "worksheet": "å…¬è¡†ãƒˆã‚¤ãƒ¬",
        "fields": BASE_FIELDS,
        "included_types": [],
        "search_terms": ["ãƒˆã‚¤ãƒ¬", "å…¬è¡†ãƒˆã‚¤ãƒ¬", "ä¾¿æ‰€", "åŒ–ç²§å®¤"]
    }
}

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰
HEADERS = {
    "é£²é£Ÿåº—": [
        "ãƒ—ãƒ¬ã‚¤ã‚¹ID", "åº—èˆ—å", "ä½æ‰€", "ç·¯åº¦", "çµŒåº¦", 
        "ã‚«ãƒ†ã‚´ãƒª", "ã‚«ãƒ†ã‚´ãƒªè©³ç´°", "é›»è©±ç•ªå·", "å–¶æ¥­æ™‚é–“", 
        "è©•ä¾¡", "ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°", "åœ°åŒº", "Googleãƒãƒƒãƒ—URL", "æœ€çµ‚æ›´æ–°æ—¥æ™‚"
    ],
    "é§è»Šå ´": [
        "ãƒ—ãƒ¬ã‚¤ã‚¹ID", "é§è»Šå ´å", "æ‰€åœ¨åœ°", "ç·¯åº¦", "çµŒåº¦",
        "ã‚«ãƒ†ã‚´ãƒª", "ã‚«ãƒ†ã‚´ãƒªè©³ç´°", "åœ°åŒº", "Googleãƒãƒƒãƒ—URL", "æœ€çµ‚æ›´æ–°æ—¥æ™‚"
    ],
    "å…¬è¡†ãƒˆã‚¤ãƒ¬": [
        "ãƒ—ãƒ¬ã‚¤ã‚¹ID", "æ–½è¨­å", "æ‰€åœ¨åœ°", "ç·¯åº¦", "çµŒåº¦", 
        "ã‚«ãƒ†ã‚´ãƒª", "ã‚«ãƒ†ã‚´ãƒªè©³ç´°", "åœ°åŒº", "Googleãƒãƒƒãƒ—URL", "æœ€çµ‚æ›´æ–°æ—¥æ™‚"
    ]
}

NOT_FOUND_HEADERS = ["æ¤œç´¢èª", "å®Ÿéš›ã®æ¤œç´¢èª", "æ¤œç´¢æ—¥", "è©¦è¡Œå›æ•°", "ã‚«ãƒ†ã‚´ãƒª"]

def normalize_address(address):
    """ä½æ¸¡ã®ä½æ‰€ã‚’æ­£è¦åŒ–"""
    replacements = {
        'æ–°æ½ŸçœŒä½æ¸¡å¸‚': 'ä½æ¸¡å¸‚',
        'ä½æ¸¡éƒ¡': 'ä½æ¸¡å¸‚',
        'ä¸¡æ´¥å¸‚': 'ä½æ¸¡å¸‚ä¸¡æ´¥',
        'ç›¸å·ç”º': 'ä½æ¸¡å¸‚ç›¸å·',
        'ä½å’Œç”°ç”º': 'ä½æ¸¡å¸‚ä½å’Œç”°',
        'é‡‘äº•ç”º': 'ä½æ¸¡å¸‚é‡‘äº•',
        'æ–°ç©‚æ‘': 'ä½æ¸¡å¸‚æ–°ç©‚',
        'ç•‘é‡ç”º': 'ä½æ¸¡å¸‚ç•‘é‡',
        'çœŸé‡ç”º': 'ä½æ¸¡å¸‚çœŸé‡',
        'å°æœ¨ç”º': 'ä½æ¸¡å¸‚å°æœ¨',
        'ç¾½èŒ‚ç”º': 'ä½æ¸¡å¸‚ç¾½èŒ‚',
        'èµ¤æ³Šæ‘': 'ä½æ¸¡å¸‚èµ¤æ³Š'
    }
    
    normalized = address
    for old, new in replacements.items():
        normalized = normalized.replace(old, new)
    
    return normalized

def classify_district(address):
    """ä½æ‰€ã‹ã‚‰åœ°åŒºã‚’åˆ†é¡"""
    normalized_address = normalize_address(address)
    
    for district, areas in SADO_DISTRICTS.items():
        if any(area in normalized_address for area in areas):
            return district
    return "ãã®ä»–"

def generate_search_queries(query, category):
    """æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’ã€Œ<ã‚¯ã‚¨ãƒª> ä½æ¸¡ã€ã®å½¢å¼ã«çµ±ä¸€"""
    if "ä½æ¸¡" not in query:
        return [f"{query} ä½æ¸¡"]
    return [query]

def search_places_multi_pattern(query, category):
    """ç”Ÿæˆã•ã‚ŒãŸæ¤œç´¢ã‚¯ã‚¨ãƒªã§å ´æ‰€ã‚’æ¤œç´¢ã™ã‚‹"""
    search_queries = generate_search_queries(query, category)
    
    for i, search_query in enumerate(search_queries):
        print(f"  Trying pattern {i+1}/{len(search_queries)}: '{search_query}'")
        
        status, places = search_places_new_api(search_query, category)
        
        if status == 'OK' and places:
            print(f"  âœ“ Found {len(places)} places with pattern {i+1}")
            return status, places, search_query
        
        if status == 'REQUEST_FAILED':
            return status, [], search_query
            
        # çŸ­ã„å¾…æ©Ÿæ™‚é–“
        if i < len(search_queries) - 1:
            time.sleep(0.5)
    
    print(f"  âœ— No results found with any pattern")
    return 'ZERO_RESULTS', [], search_queries[0]

def search_places_new_api(text_query, category):
    """æ–°ã—ã„Places APIï¼ˆText Searchï¼‰ã‚’ä½¿ç”¨ã—ã¦å ´æ‰€ã‚’æ¤œç´¢"""
    if not PLACES_API_KEY:
        print("PLACES_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return 'SKIPPED', []
    
    config = CATEGORIES[category]
    
    # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚’æ§‹ç¯‰
    request_body = {
        "textQuery": text_query,
        "languageCode": "ja",
        "maxResultCount": 20,
        "locationBias": {
            "rectangle": {
                "low": {"latitude": SADO_BOUNDS["south"], "longitude": SADO_BOUNDS["west"]},
                "high": {"latitude": SADO_BOUNDS["north"], "longitude": SADO_BOUNDS["east"]}
            }
        }
    }
    
    # ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ã¦ãƒ•ã‚£ãƒ«ã‚¿ã‚’è¿½åŠ 
    if config["included_types"]:
        request_body["includedType"] = config["included_types"][0]
    
    headers = {
        'Content-Type': 'application/json',
        'X-Goog-Api-Key': PLACES_API_KEY,
        'X-Goog-FieldMask': ','.join(config["fields"])
    }
    
    try:
        response = requests.post(
            'https://places.googleapis.com/v1/places:searchText',
            headers=headers,
            json=request_body
        )
        response.raise_for_status()
        data = response.json()
        
        places = data.get('places', [])
        return 'OK' if places else 'ZERO_RESULTS', places
        
    except requests.exceptions.RequestException as e:
        print(f"API request failed: {e}")
        return 'REQUEST_FAILED', []

def determine_category_from_place(place):
    """å ´æ‰€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®šï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    name = place.get('displayName', {}).get('text', '').lower()
    address = place.get('shortFormattedAddress', '').lower()
    primary_type = place.get('primaryType', '')
    
    # åå‰ã¨ä½æ‰€ã«ã‚ˆã‚‹åˆ¤å®šï¼ˆå„ªå…ˆï¼‰
    toilet_keywords = ["ãƒˆã‚¤ãƒ¬", "ä¾¿æ‰€", "åŒ–ç²§å®¤", "restroom", "toilet"]
    parking_keywords = ["é§è»Š", "parking", "ãƒ‘ãƒ¼ã‚­ãƒ³ã‚°"]
    
    if any(keyword in name for keyword in toilet_keywords) or any(keyword in address for keyword in toilet_keywords):
        return "å…¬è¡†ãƒˆã‚¤ãƒ¬"
    
    if any(keyword in name for keyword in parking_keywords) or any(keyword in address for keyword in parking_keywords):
        return "é§è»Šå ´"
    
    # ãƒ—ãƒ©ã‚¤ãƒãƒªã‚¿ã‚¤ãƒ—ã«ã‚ˆã‚‹åˆ¤å®š
    if primary_type == "parking":
        return "é§è»Šå ´"
    elif primary_type in ["restaurant", "meal_takeaway", "cafe", "bar", "bakery", "food"]:
        return "é£²é£Ÿåº—"
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯é£²é£Ÿåº—
    return "é£²é£Ÿåº—"

def format_detailed_opening_hours(opening_hours_data):
    """å–¶æ¥­æ™‚é–“ãƒ‡ãƒ¼ã‚¿ã‚’è©³ç´°ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if not opening_hours_data:
        return ""
    
    # weekdayTextãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’å„ªå…ˆ
    weekday_text = opening_hours_data.get('weekdayText', [])
    if weekday_text:
        return "\n".join(weekday_text)
    
    # periodsã‹ã‚‰æ§‹ç¯‰
    periods = opening_hours_data.get('periods', [])
    if not periods:
        return ""
    
    formatted_hours = []
    days = ['æ—¥', 'æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ']
    
    for period in periods:
        open_time = period.get('open', {})
        close_time = period.get('close', {})
        
        day = open_time.get('day', 0)
        day_name = days[day] if 0 <= day < 7 else str(day)
        
        open_hour = f"{open_time.get('hour', 0):02d}:{open_time.get('minute', 0):02d}"
        
        if close_time:
            close_hour = f"{close_time.get('hour', 0):02d}:{close_time.get('minute', 0):02d}"
            formatted_hours.append(f"{day_name}: {open_hour}-{close_hour}")
        else:
            formatted_hours.append(f"{day_name}: {open_hour}-24:00")
    
    return "\n".join(formatted_hours)

def extract_place_data(place, category):
    """å ´æ‰€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¿…è¦ãªæƒ…å ±ã‚’æŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    place_id = place.get('id', '')
    name = place.get('displayName', {}).get('text', '')
    raw_address = place.get('shortFormattedAddress', '')
    address = normalize_address(raw_address)
    
    location = place.get('location', {})
    lat = location.get('latitude', '')
    lng = location.get('longitude', '')
    
    primary_type = place.get('primaryType', '')
    primary_type_display = place.get('primaryTypeDisplayName', {}).get('text', '')
    
    # åœ°åŒºåˆ†é¡
    district = classify_district(address)
    
    # Google Mapsãƒªãƒ³ã‚¯ã¯previewãªã®ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯URLã‚’ç”Ÿæˆ
    google_maps_url = ""
    if 'googleMapsLinks' in place and place['googleMapsLinks']:
        google_maps_url = place['googleMapsLinks'].get('directionsLink', 
                         place['googleMapsLinks'].get('searchLink', ''))
    
    if not google_maps_url and place_id:
        google_maps_url = f"https://www.google.com/maps/search/?api=1&query=Google&query_place_id={place_id}"
    
    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
    
    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’æœ€é©åŒ–
    if category == "é£²é£Ÿåº—":
        phone = place.get('nationalPhoneNumber', '')
        opening_hours = format_detailed_opening_hours(place.get('regularOpeningHours'))
        rating = place.get('rating', '')
        review_count = place.get('userRatingCount', '')
        
        return [
            place_id, name, address, lat, lng,
            primary_type, primary_type_display, phone, opening_hours,
            rating, review_count, district, google_maps_url, timestamp
        ]
    
    else:
        # é§è»Šå ´ãƒ»å…¬è¡†ãƒˆã‚¤ãƒ¬: ã‚·ãƒ³ãƒ—ãƒ«æ§‹æˆ
        return [
            place_id, name, address, lat, lng,
            primary_type, primary_type_display, district, google_maps_url, timestamp
        ]

def get_or_create_worksheet(spreadsheet, worksheet_name):
    """ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã‚’å–å¾—ã¾ãŸã¯ä½œæˆ"""
    try:
        return spreadsheet.worksheet(worksheet_name)
    except gspread.exceptions.WorksheetNotFound:
        print(f"Creating worksheet: {worksheet_name}")
        return spreadsheet.add_worksheet(title=worksheet_name, rows=1000, cols=20)

def update_worksheet(spreadsheet, category, places_data):
    """ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã‚’æ›´æ–°ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    worksheet_name = CATEGORIES[category]["worksheet"]
    print(f"Updating worksheet: {worksheet_name}")
    
    worksheet = get_or_create_worksheet(spreadsheet, worksheet_name)
    
    # ãƒ˜ãƒƒãƒ€ãƒ¼ç¢ºèªãƒ»è¨­å®š
    try:
        existing_headers = worksheet.row_values(1)
    except:
        existing_headers = []
    
    expected_headers = HEADERS[category]
    if existing_headers != expected_headers:
        worksheet.update('A1', [expected_headers])
        print(f"Headers updated for {worksheet_name}")
        all_records = []
    else:
        all_records = worksheet.get_all_records()
    
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒ—ä½œæˆ
    existing_data = {
        record['ãƒ—ãƒ¬ã‚¤ã‚¹ID']: {'data': record, 'row': i + 2}
        for i, record in enumerate(all_records) 
        if record.get('ãƒ—ãƒ¬ã‚¤ã‚¹ID')
    }
    
    updates = []
    appends = []
    
    for place in places_data:
        # ã‚«ãƒ†ã‚´ãƒªåˆ¤å®š
        place_category = determine_category_from_place(place)
        if place_category != category:
            continue
            
        place_id = place.get('id', '')
        if not place_id:
            continue
            
        row_data = extract_place_data(place, category)
        
        if place_id in existing_data:
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°åˆ¤å®šï¼ˆæ”¹è‰¯ç‰ˆï¼‰
            old_data = existing_data[place_id]['data']
            row_num = existing_data[place_id]['row']
            
            # ã‚ˆã‚Šè©³ç´°ãªæ›´æ–°åˆ¤å®š
            address_field = "ä½æ‰€" if category == "é£²é£Ÿåº—" else "æ‰€åœ¨åœ°"
            needs_update = (
                str(old_data.get(address_field, '')) != str(row_data[2]) or
                str(old_data.get('åœ°åŒº', '')) != str(row_data[-3]) or  # åœ°åŒºæƒ…å ±
                (category == "é£²é£Ÿåº—" and (
                    str(old_data.get('é›»è©±ç•ªå·', '')) != str(row_data[7]) or
                    str(old_data.get('å–¶æ¥­æ™‚é–“', '')) != str(row_data[8])
                ))
            )
            
            if needs_update:
                end_col = chr(ord('A') + len(expected_headers) - 1)
                updates.append({
                    'range': f'A{row_num}:{end_col}{row_num}',
                    'values': [row_data]
                })
        else:
            appends.append(row_data)
    
    # ãƒãƒƒãƒæ›´æ–°
    if updates:
        worksheet.batch_update(updates)
        print(f"Updated {len(updates)} rows in {worksheet_name}")
        time.sleep(SHEETS_API_DELAY)
    
    if appends:
        worksheet.append_rows(appends)
        print(f"Added {len(appends)} new rows in {worksheet_name}")

def update_not_found_worksheet(spreadsheet, not_found_data):
    """æ¤œç´¢çµæœãªã—ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã‚’æ›´æ–°ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
    if not not_found_data:
        return
    
    worksheet = get_or_create_worksheet(spreadsheet, "æ¤œç´¢çµæœãªã—")
    
    try:
        existing_headers = worksheet.row_values(1)
    except:
        existing_headers = []
    
    if existing_headers != NOT_FOUND_HEADERS:
        worksheet.update('A1', [NOT_FOUND_HEADERS])
        all_records = []
    else:
        all_records = worksheet.get_all_records()
    
    # æ—¢å­˜ã‚¯ã‚¨ãƒªãƒãƒƒãƒ—
    existing_queries = {
        (record['æ¤œç´¢èª'], record['ã‚«ãƒ†ã‚´ãƒª']): {'data': record, 'row': i + 2}
        for i, record in enumerate(all_records)
        if record.get('æ¤œç´¢èª') and record.get('ã‚«ãƒ†ã‚´ãƒª')
    }
    
    current_date = time.strftime('%Y-%m-%d')
    updates = []
    appends = []
    
    for item in not_found_data:
        query = item['original_query']
        search_query = item['search_query']
        category = item['category']
        
        key = (query, category)
        
        if key in existing_queries:
            old_data = existing_queries[key]['data']
            if old_data.get('æ¤œç´¢æ—¥') == current_date:
                # è©¦è¡Œå›æ•°ã‚’å¢—ã‚„ã™
                attempts = int(old_data.get('è©¦è¡Œå›æ•°', 1)) + 1
                row_num = existing_queries[key]['row']
                updates.append({
                    'range': f'A{row_num}:E{row_num}',
                    'values': [[query, search_query, current_date, attempts, category]]
                })
            else:
                appends.append([query, search_query, current_date, 1, category])
        else:
            appends.append([query, search_query, current_date, 1, category])
    
    if updates:
        worksheet.batch_update(updates)
    if appends:
        worksheet.append_rows(appends)

def authenticate_google_sheets():
    """Google Sheetsèªè¨¼"""
    creds_json_str = os.environ.get('GOOGLE_SERVICE_ACCOUNT_KEY')
    
    try:
        if creds_json_str:
            creds_dict = json.loads(creds_json_str)
            return gspread.service_account_from_dict(creds_dict)
        else:
            return gspread.service_account(filename=SERVICE_ACCOUNT_FILE_PATH)
    except Exception as e:
        print(f"Googleèªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return None

def load_queries_from_file(filename):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¯ã‚¨ãƒªã‚’èª­ã¿è¾¼ã¿"""
    file_path = os.path.join(SCRIPT_DIR, filename)
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            queries = [line.strip() for line in f 
                      if line.strip() and not line.strip().startswith('#')]
        print(f"Loaded {len(queries)} queries from {filename}")
        return queries
    except FileNotFoundError:
        print(f"Warning: {filename} not found")
        return []

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
    if not PLACES_API_KEY or not SPREADSHEET_ID:
        print("Error: PLACES_API_KEY or SPREADSHEET_ID not set")
        return
    
    print(f"ğŸ¯ Target data: {TARGET_DATA}")
    print(f"â±ï¸ API delay: {API_REQUEST_DELAY}s")
    
    # Google Sheetsèªè¨¼
    gc = authenticate_google_sheets()
    if not gc:
        return
    
    try:
        spreadsheet = gc.open_by_key(SPREADSHEET_ID)
    except Exception as e:
        print(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚ªãƒ¼ãƒ—ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")
        return
    
    # ã‚¯ã‚¨ãƒªãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆTARGET_DATAã«åŸºã¥ãé¸æŠçš„å‡¦ç†ï¼‰
    query_files = {
        'é£²é£Ÿåº—': 'restaurants.txt',
        'å…¬è¡†ãƒˆã‚¤ãƒ¬': 'toilets.txt', 
        'é§è»Šå ´': 'parkings.txt'
    }
    
    # TARGET_DATAã«ã‚ˆã‚‹çµã‚Šè¾¼ã¿
    if TARGET_DATA != 'all':
        category_mapping = {
            'restaurants': 'é£²é£Ÿåº—',
            'toilets': 'å…¬è¡†ãƒˆã‚¤ãƒ¬', 
            'parkings': 'é§è»Šå ´'
        }
        
        if TARGET_DATA in category_mapping:
            category = category_mapping[TARGET_DATA]
            query_files = {category: query_files[category]}
            print(f"ğŸ“ Processing only: {category}")
        else:
            print(f"âŒ Unknown target data: {TARGET_DATA}")
            return
    
    all_not_found = []
    total_api_calls = 0
    
    for category, filename in query_files.items():
        queries = load_queries_from_file(filename)
        if not queries:
            continue
        
        print(f"\n=== Processing {category} ({len(queries)} queries) ===")
        all_places = []
        category_not_found = []
        
        for i, query in enumerate(queries, 1):
            print(f"[{i}/{len(queries)}] Processing: {query}")
            
            status, places, search_query = search_places_multi_pattern(query, category)
            total_api_calls += len(generate_search_queries(query, category))
            
            if status == 'ZERO_RESULTS':
                category_not_found.append({
                    'original_query': query,
                    'search_query': search_query,
                    'category': category
                })
            elif status == 'OK':
                all_places.extend(places)
            elif status == 'REQUEST_FAILED':
                print(f"  âš ï¸ API request failed for: {query}")
                break
            
            time.sleep(API_REQUEST_DELAY)
        
        # é‡è¤‡é™¤å»
        unique_places = list({place['id']: place for place in all_places 
                            if place.get('id')}.values())
        
        print(f"Found {len(unique_places)} unique places for {category}")
        
        # ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆæ›´æ–°
        if unique_places:
            update_worksheet(spreadsheet, category, unique_places)
        
        all_not_found.extend(category_not_found)
        time.sleep(SHEETS_API_DELAY)
    
    # æ¤œç´¢çµæœãªã—ã®è¨˜éŒ²
    if all_not_found:
        update_not_found_worksheet(spreadsheet, all_not_found)
        print(f"\n{len(all_not_found)} queries had no results")
    
    # ã‚³ã‚¹ãƒˆè¨ˆç®—è¡¨ç¤º
    cost_per_request = 0.017  # Text Search (New) ã®æ–™é‡‘ (USD)
    estimated_cost = total_api_calls * cost_per_request
    
    print(f"\nâœ… Process completed!")
    print(f"ğŸ“Š Total API calls made: approximately {total_api_calls}")
    print(f"ğŸ’° Estimated cost: ${estimated_cost:.3f} USD (${cost_per_request} per request)")
    print(f"ğŸ“… Target data: {TARGET_DATA}")

if __name__ == '__main__':
    main()