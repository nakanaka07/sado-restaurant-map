#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰‹å‹•URLã«ã‚ˆã‚‹è£œå®Œæ›´æ–°ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
é€šå¸¸æ¤œç´¢ã§è¦‹ã¤ã‹ã‚‰ãªã„åº—èˆ—ã‚’æ‰‹å‹•URLã§è£œå®Œ

ä½¿ç”¨æ‰‹é †:
1. é€šå¸¸ã®run_optimized.pyã‚’å®Ÿè¡Œ
2. è¦‹ã¤ã‹ã‚‰ãªã„åº—èˆ—ã‚’æ‰‹å‹•ã§Google Mapsã§æ¤œç´¢
3. URLã‚’ missing_restaurants_urls.txt ã«ä¿å­˜
4. ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§è£œå®Œå®Ÿè¡Œ
"""

import os
import sys
import gspread
import pandas as pd
from datetime import datetime
from manual_url_extractor import URLToPlaceExtractor

def complement_missing_restaurants():
    """æ‰‹å‹•URLã§è¦‹ã¤ã‹ã‚‰ãªã„åº—èˆ—ã‚’è£œå®Œ"""
    
    # URLãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    url_file = 'missing_restaurants_urls.txt'
    if not os.path.exists(url_file):
        print(f"âŒ {url_file} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("æ‰‹å‹•ã§æ¤œç´¢ã—ãŸåº—èˆ—ã®URLã‚’ä»¥ä¸‹ã®å½¢å¼ã§ä¿å­˜ã—ã¦ãã ã•ã„ï¼š")
        print("https://www.google.com/maps/place/åº—èˆ—å/@ç·¯åº¦,çµŒåº¦,zoom/data=...")
        return
    
    # URLã‚’èª­ã¿è¾¼ã¿
    with open(url_file, 'r', encoding='utf-8') as f:
        urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    
    if not urls:
        print(f"âŒ {url_file} ã«URLãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print(f"ğŸ“‹ {len(urls)}å€‹ã®æ‰‹å‹•URLã‚’å‡¦ç†ä¸­...")
    
    # URLå‡¦ç†
    extractor = URLToPlaceExtractor()
    results = []
    
    for i, url in enumerate(urls, 1):
        print(f"\n[{i}/{len(urls)}]")
        result = extractor.process_url(url)
        if result and result.get('details'):
            # çµæœã‚’æ•´å½¢
            details = result['details']
            location = details.get('geometry', {}).get('location', {})
            
            formatted_result = {
                'åº—èˆ—å': details.get('name', ''),
                'ä½æ‰€': details.get('formatted_address', ''),
                'ç·¯åº¦': location.get('lat', ''),
                'çµŒåº¦': location.get('lng', ''),
                'è©•ä¾¡': details.get('rating', ''),
                'ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°': details.get('user_ratings_total', ''),
                'å–¶æ¥­çŠ¶æ³': translate_business_status(details.get('business_status', '')),
                'é›»è©±ç•ªå·': details.get('formatted_phone_number', ''),
                'ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ': details.get('website', ''),
                'Place ID': details.get('place_id', ''),
                'å–å¾—æ–¹æ³•': 'Manual URL',
                'å…ƒURL': url,
                'æ›´æ–°æ—¥æ™‚': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            results.append(formatted_result)
    
    if not results:
        print("âŒ URLã‹ã‚‰åº—èˆ—æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # Google Sheetsã«è¿½åŠ 
    save_to_sheets(results)

def translate_business_status(status):
    """å–¶æ¥­çŠ¶æ³ã‚’æ—¥æœ¬èªã«ç¿»è¨³"""
    status_map = {
        'OPERATIONAL': 'å–¶æ¥­ä¸­',
        'CLOSED_TEMPORARILY': 'ä¸€æ™‚ä¼‘æ¥­',
        'CLOSED_PERMANENTLY': 'é–‰åº—',
        '': 'ä¸æ˜'
    }
    return status_map.get(status, status)

def save_to_sheets(results, sheet_name='é£²é£Ÿåº—_æ‰‹å‹•è£œå®Œ'):
    """Google Sheetsã«çµæœã‚’ä¿å­˜"""
    try:
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šå–å¾—
        from dotenv import load_dotenv
        load_dotenv()
        
        SPREADSHEET_ID = os.environ.get('SPREADSHEET_ID')
        if not SPREADSHEET_ID:
            print("âŒ SPREADSHEET_ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return
        
        # Google Sheetsèªè¨¼
        gc = gspread.service_account()
        spreadsheet = gc.open_by_key(SPREADSHEET_ID)
        
        # ã‚·ãƒ¼ãƒˆã‚’å–å¾—ã¾ãŸã¯ä½œæˆ
        try:
            worksheet = spreadsheet.worksheet(sheet_name)
            print(f"ğŸ“ æ—¢å­˜ã‚·ãƒ¼ãƒˆ '{sheet_name}' ã«è¿½åŠ ")
            
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            existing_data = worksheet.get_all_records()
            df_existing = pd.DataFrame(existing_data) if existing_data else pd.DataFrame()
            
        except gspread.WorksheetNotFound:
            # æ–°ã—ã„ã‚·ãƒ¼ãƒˆã‚’ä½œæˆ
            worksheet = spreadsheet.add_worksheet(
                title=sheet_name,
                rows=len(results) + 10,
                cols=len(results[0]) if results else 15
            )
            print(f"âœ¨ æ–°è¦ã‚·ãƒ¼ãƒˆ '{sheet_name}' ã‚’ä½œæˆ")
            df_existing = pd.DataFrame()
        
        # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿
        df_new = pd.DataFrame(results)
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
        if not df_existing.empty:
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆPlace IDãƒ™ãƒ¼ã‚¹ï¼‰
            if 'Place ID' in df_existing.columns:
                existing_place_ids = set(df_existing['Place ID'].tolist())
                df_new = df_new[~df_new['Place ID'].isin(existing_place_ids)]
                print(f"ğŸ“Š é‡è¤‡é™¤å»å¾Œ: {len(df_new)}ä»¶ã®æ–°è¦ãƒ‡ãƒ¼ã‚¿")
            
            if not df_new.empty:
                df_combined = pd.concat([df_existing, df_new], ignore_index=True)
            else:
                print("âš ï¸ æ–°è¦ãƒ‡ãƒ¼ã‚¿ã¯ã™ã¹ã¦é‡è¤‡ã—ã¦ã„ã¾ã—ãŸ")
                return
        else:
            df_combined = df_new
        
        # ã‚·ãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¦å…¨ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿
        worksheet.clear()
        data_to_write = [list(df_combined.columns)] + df_combined.values.tolist()
        worksheet.update(values=data_to_write, range_name='A1')
        
        print(f"âœ… {len(df_new)}ä»¶ã®æ–°è¦ãƒ‡ãƒ¼ã‚¿ã‚’{sheet_name}ã«ä¿å­˜")
        print(f"ğŸ“Š ç·ä»¶æ•°: {len(df_combined)}ä»¶")
        print(f"ğŸ”— Spreadsheet: https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}")
        
    except Exception as e:
        print(f"âŒ Google Sheetsä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == '__main__':
    complement_missing_restaurants()
