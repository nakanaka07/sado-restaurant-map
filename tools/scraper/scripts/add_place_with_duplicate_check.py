#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡è¤‡ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ä»˜ãåº—èˆ—è¿½åŠ ã‚·ã‚¹ãƒ†ãƒ 

æ–°åº—èˆ—è¿½åŠ æ™‚ã«æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨ã®é‡è¤‡ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€å®‰å…¨ã«è¿½åŠ ã‚’è¡Œã„ã¾ã™ã€‚

ä½¿ç”¨ä¾‹:
    python scripts/add_place_with_duplicate_check.py --restaurant "https://www.google.com/maps/place/..."
    python scripts/add_place_with_duplicate_check.py --parking "https://www.google.com/maps/place/..."
    python scripts/add_place_with_duplicate_check.py --toilet "https://www.google.com/maps/place/..."
    python scripts/add_place_with_duplicate_check.py --check-all  # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
"""

import argparse
import re
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Set
from dataclasses import dataclass
from difflib import SequenceMatcher
from new_url_converter import AdvancedURLConverter


@dataclass
class PlaceEntry:
    """åº—èˆ—ãƒ»æ–½è¨­ã‚¨ãƒ³ãƒˆãƒªãƒ¼"""
    cid: Optional[str]
    name: Optional[str]
    original_line: str
    file_source: str
    line_number: int


class DuplicateChecker:
    """é‡è¤‡ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.converter = AdvancedURLConverter()
        self.data_dir = Path('data')

        # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°
        self.category_files = {
            'restaurants': self.data_dir / 'restaurants_merged.txt',
            'parkings': self.data_dir / 'parkings_merged.txt',
            'toilets': self.data_dir / 'toilets_merged.txt'
        }

    def parse_file_entries(self, file_path: Path) -> List[PlaceEntry]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’è§£æ"""
        entries = []

        if not file_path.exists():
            return entries

        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            for line_num, line in enumerate(lines, 1):
                entry = self._parse_single_line(line, line_num, file_path.name)
                if entry:
                    entries.append(entry)

        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¨ãƒ©ãƒ¼ {file_path.name}: {e}")

        return entries

    def _parse_single_line(self, line: str, line_num: int, file_name: str) -> Optional[PlaceEntry]:
        """å˜ä¸€è¡Œã‚’è§£æã—ã¦PlaceEntryã‚’ä½œæˆ"""
        line = line.strip()

        # ç©ºè¡Œã‚„ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã¯ã‚¹ã‚­ãƒƒãƒ—
        if not line or line.startswith('#'):
            return None

        # CIDã¨nameã‚’æŠ½å‡º
        cid, name = self._extract_cid_and_name(line)

        return PlaceEntry(
            cid=cid,
            name=name,
            original_line=line,
            file_source=file_name,
            line_number=line_num
        )

    def _extract_cid_and_name(self, line: str) -> Tuple[Optional[str], Optional[str]]:
        """è¡Œã‹ã‚‰CIDã¨åå‰ã‚’æŠ½å‡º"""
        cid = None
        name = None

        # CID URLå½¢å¼ã®å ´åˆ
        if 'maps.google.com/place?cid=' in line:
            cid_match = re.search(r'cid=(\d+)', line)
            if cid_match:
                cid = cid_match.group(1)

            # ã‚³ãƒ¡ãƒ³ãƒˆéƒ¨åˆ†ã‹ã‚‰åå‰ã‚’æŠ½å‡º
            name_match = re.search(r'#\s*(.+)', line)
            if name_match:
                name = name_match.group(1).strip()

        # é€šå¸¸ã®Google Maps URLã®å ´åˆ
        elif 'google.com/maps/place/' in line:
            # URLå¤‰æ›ã‚’è©¦è¡Œ
            _, _, extracted_cid, extracted_name = self.converter.convert_url_to_cid_format(line)
            cid = extracted_cid
            name = extracted_name

        # ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®å ´åˆ
        else:
            name = line

        return cid, name

    def get_all_entries(self) -> Dict[str, List[PlaceEntry]]:
        """å…¨ã‚«ãƒ†ã‚´ãƒªã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’å–å¾—"""
        all_entries = {}

        for category, file_path in self.category_files.items():
            entries = self.parse_file_entries(file_path)
            all_entries[category] = entries
            print(f"ğŸ“Š {category}: {len(entries)}ä»¶ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’èª­ã¿è¾¼ã¿")

        return all_entries

    def find_duplicates_by_cid(self, all_entries: Dict[str, List[PlaceEntry]]) -> List[Tuple[PlaceEntry, PlaceEntry]]:
        """CIDã«ã‚ˆã‚‹é‡è¤‡ã‚’æ¤œç´¢"""
        duplicates = []
        cid_to_entry = {}

        for category, entries in all_entries.items():
            for entry in entries:
                if entry.cid:
                    if entry.cid in cid_to_entry:
                        # é‡è¤‡ç™ºè¦‹
                        duplicates.append((cid_to_entry[entry.cid], entry))
                    else:
                        cid_to_entry[entry.cid] = entry

        return duplicates

    def find_duplicates_by_name(self, all_entries: Dict[str, List[PlaceEntry]], similarity_threshold: float = 0.8) -> List[Tuple[PlaceEntry, PlaceEntry]]:
        """åå‰ã«ã‚ˆã‚‹é‡è¤‡ã‚’æ¤œç´¢ï¼ˆé¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹ï¼‰"""
        duplicates = []
        all_entries_flat = self._flatten_entries(all_entries)

        # å„ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã¨ä»–ã®å…¨ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’æ¯”è¼ƒ
        for i, entry1 in enumerate(all_entries_flat):
            for entry2 in all_entries_flat[i+1:]:
                if self._are_names_similar(entry1, entry2, similarity_threshold):
                    duplicates.append((entry1, entry2))

        return duplicates

    def _flatten_entries(self, all_entries: Dict[str, List[PlaceEntry]]) -> List[PlaceEntry]:
        """å…¨ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–"""
        all_entries_flat = []
        for category, entries in all_entries.items():
            for entry in entries:
                if entry.name:
                    all_entries_flat.append(entry)
        return all_entries_flat

    def _are_names_similar(self, entry1: PlaceEntry, entry2: PlaceEntry, threshold: float) -> bool:
        """2ã¤ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã®åå‰ãŒé¡ä¼¼ã—ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        if not (entry1.name and entry2.name):
            return False

        similarity = SequenceMatcher(None, entry1.name.lower(), entry2.name.lower()).ratio()
        return similarity >= threshold

    def check_new_entry_duplicates(self, new_url: str, target_category: str) -> Dict[str, any]:
        """æ–°ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯"""
        result = self._initialize_duplicate_check_result()

        # æ–°ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’è§£æ
        new_entry = self._create_new_entry(new_url, target_category, result)
        if 'error' in result:
            return result

        result['new_entry'] = new_entry

        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦é‡è¤‡ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
        all_entries = self.get_all_entries()
        self._check_cid_duplicates(new_entry, all_entries, result)
        self._check_name_duplicates(new_entry, all_entries, result)
        self._generate_recommendations(result)

        return result

    def _initialize_duplicate_check_result(self) -> Dict[str, any]:
        """é‡è¤‡ãƒã‚§ãƒƒã‚¯çµæœã®åˆæœŸåŒ–"""
        return {
            'has_duplicates': False,
            'cid_duplicates': [],
            'name_duplicates': [],
            'new_entry': None,
            'recommendations': []
        }

    def _create_new_entry(self, new_url: str, target_category: str, result: Dict[str, any]) -> Optional[PlaceEntry]:
        """æ–°ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’ä½œæˆ"""
        conversion_result = self.converter.convert_single_url(new_url)

        if not conversion_result['success']:
            result['error'] = f"URLå¤‰æ›å¤±æ•—: {conversion_result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}"
            return None

        return PlaceEntry(
            cid=conversion_result['cid'],
            name=conversion_result['place_name'],
            original_line=new_url,
            file_source=f"æ–°è¦è¿½åŠ ({target_category})",
            line_number=0
        )

    def _check_cid_duplicates(self, new_entry: PlaceEntry, all_entries: Dict[str, List[PlaceEntry]], result: Dict[str, any]) -> None:
        """CIDã«ã‚ˆã‚‹é‡è¤‡ãƒã‚§ãƒƒã‚¯"""
        if not new_entry.cid:
            return

        for category, entries in all_entries.items():
            for entry in entries:
                if entry.cid == new_entry.cid:
                    result['cid_duplicates'].append({
                        'category': category,
                        'entry': entry,
                        'match_type': 'CIDå®Œå…¨ä¸€è‡´'
                    })

    def _check_name_duplicates(self, new_entry: PlaceEntry, all_entries: Dict[str, List[PlaceEntry]], result: Dict[str, any]) -> None:
        """åå‰ã«ã‚ˆã‚‹é‡è¤‡ãƒã‚§ãƒƒã‚¯"""
        if not new_entry.name:
            return

        for category, entries in all_entries.items():
            for entry in entries:
                if entry.name:
                    similarity = SequenceMatcher(None, new_entry.name.lower(), entry.name.lower()).ratio()
                    if similarity >= 0.8:  # 80%ä»¥ä¸Šã®é¡ä¼¼åº¦
                        result['name_duplicates'].append({
                            'category': category,
                            'entry': entry,
                            'similarity': similarity,
                            'match_type': f'åå‰é¡ä¼¼({similarity:.1%})'
                        })

    def _generate_recommendations(self, result: Dict[str, any]) -> None:
        """æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç”Ÿæˆ"""
        result['has_duplicates'] = bool(result['cid_duplicates'] or result['name_duplicates'])

        if result['has_duplicates']:
            if result['cid_duplicates']:
                result['recommendations'].append("âŒ åŒã˜CIDã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãŒæ—¢ã«å­˜åœ¨ã—ã¾ã™ã€‚è¿½åŠ ã‚’ä¸­æ­¢ã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")
            if result['name_duplicates']:
                result['recommendations'].append("âš ï¸ é¡ä¼¼ã™ã‚‹åå‰ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãŒå­˜åœ¨ã—ã¾ã™ã€‚ç¢ºèªã—ã¦ã‹ã‚‰è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")
        else:
            result['recommendations'].append("âœ… é‡è¤‡ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚å®‰å…¨ã«è¿½åŠ ã§ãã¾ã™ã€‚")

    def generate_duplicate_report(self, all_entries: Dict[str, List[PlaceEntry]]) -> str:
        """é‡è¤‡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        cid_duplicates = self.find_duplicates_by_cid(all_entries)
        name_duplicates = self.find_duplicates_by_name(all_entries)

        report = [
            "ğŸ“Š é‡è¤‡ãƒã‚§ãƒƒã‚¯çµæœãƒ¬ãƒãƒ¼ãƒˆ",
            "=" * 50,
            f"ğŸ“ˆ ç·ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ•°: {sum(len(entries) for entries in all_entries.values())}ä»¶",
            f"ğŸ” CIDé‡è¤‡: {len(cid_duplicates)}çµ„",
            f"ğŸ“ åå‰é‡è¤‡: {len(name_duplicates)}çµ„",
        ]

        if cid_duplicates:
            report.append("\nğŸš¨ CIDé‡è¤‡ï¼ˆåŒã˜å ´æ‰€ï¼‰:")
            for i, (entry1, entry2) in enumerate(cid_duplicates, 1):
                report.append(f"  {i}. CID: {entry1.cid}")
                report.append(f"     - {entry1.file_source}:{entry1.line_number} â†’ {entry1.name}")
                report.append(f"     - {entry2.file_source}:{entry2.line_number} â†’ {entry2.name}")

        if name_duplicates:
            report.append("\nâš ï¸ åå‰é¡ä¼¼ï¼ˆè¦ç¢ºèªï¼‰:")
            for i, (entry1, entry2) in enumerate(name_duplicates, 1):
                from difflib import SequenceMatcher
                similarity = SequenceMatcher(None, entry1.name.lower(), entry2.name.lower()).ratio()
                report.append(f"  {i}. é¡ä¼¼åº¦: {similarity:.1%}")
                report.append(f"     - {entry1.file_source}:{entry1.line_number} â†’ {entry1.name}")
                report.append(f"     - {entry2.file_source}:{entry2.line_number} â†’ {entry2.name}")

        if not cid_duplicates and not name_duplicates:
            report.append("\nâœ… é‡è¤‡ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

        return "\n".join(report)

    def add_with_duplicate_check(self, category: str, url: str, force: bool = False) -> bool:
        """é‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãã§ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’è¿½åŠ """
        print(f"ğŸ” é‡è¤‡ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œä¸­: {category}")

        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
        check_result = self.check_new_entry_duplicates(url, category)
        if 'error' in check_result:
            print(f"âŒ {check_result['error']}")
            return False

        # çµæœè¡¨ç¤º
        self._display_new_entry_info(check_result['new_entry'])

        # é‡è¤‡å‡¦ç†
        if check_result['has_duplicates']:
            if not self._handle_duplicates(check_result, force):
                return False
        else:
            print("âœ… é‡è¤‡ãªã— - å®‰å…¨ã«è¿½åŠ å¯èƒ½")

        # ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½åŠ 
        return self._add_to_file(category, check_result['new_entry'])

    def _display_new_entry_info(self, new_entry: PlaceEntry) -> None:
        """æ–°ã‚¨ãƒ³ãƒˆãƒªãƒ¼æƒ…å ±ã‚’è¡¨ç¤º"""
        print(f"ğŸ“¥ æ–°ã‚¨ãƒ³ãƒˆãƒªãƒ¼: {new_entry.name}")
        if new_entry.cid:
            print(f"ğŸ“ CID: {new_entry.cid}")

    def _handle_duplicates(self, check_result: Dict[str, any], force: bool) -> bool:
        """é‡è¤‡ã®å‡¦ç†"""
        print("\nğŸš¨ é‡è¤‡ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ:")

        # CIDé‡è¤‡è¡¨ç¤º
        for dup in check_result['cid_duplicates']:
            entry = dup['entry']
            print(f"  âŒ CIDé‡è¤‡: {entry.file_source}:{entry.line_number} â†’ {entry.name}")

        # åå‰é‡è¤‡è¡¨ç¤º
        for dup in check_result['name_duplicates']:
            entry = dup['entry']
            print(f"  âš ï¸ åå‰é¡ä¼¼({dup['similarity']:.1%}): {entry.file_source}:{entry.line_number} â†’ {entry.name}")

        # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³è¡¨ç¤º
        for rec in check_result['recommendations']:
            print(f"  {rec}")

        if not force:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¢ºèª
            response = input("\nç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").lower().strip()
            if response != 'y':
                print("âŒ è¿½åŠ ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
                return False

        return True

    def _add_to_file(self, category: str, new_entry: PlaceEntry) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½åŠ """
        file_path = self.category_files[category]

        if not file_path.exists():
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
            return False

        try:
            converted_line = new_entry.original_line
            if new_entry.cid and new_entry.name:
                converted_line = f"https://maps.google.com/place?cid={new_entry.cid}  # {new_entry.name}"

            with open(file_path, 'a', encoding='utf-8') as f:
                f.write(f"\n{converted_line}")

            print(f"âœ… è¿½åŠ å®Œäº†: {file_path.name}")
            return True

        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description='é‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãæ–°åº—èˆ—è¿½åŠ ãƒ„ãƒ¼ãƒ«',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('--restaurant', help='ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³URLã‚’é‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãã§è¿½åŠ ')
    group.add_argument('--parking', help='é§è»Šå ´URLã‚’é‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãã§è¿½åŠ ')
    group.add_argument('--toilet', help='ãƒˆã‚¤ãƒ¬URLã‚’é‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãã§è¿½åŠ ')
    group.add_argument('--check-all', action='store_true', help='å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ')
    group.add_argument('--check-url', help='æ–°URLã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ã®ã¿å®Ÿè¡Œï¼ˆè¿½åŠ ã¯ã—ãªã„ï¼‰')

    parser.add_argument('--force', action='store_true', help='é‡è¤‡ãŒã‚ã£ã¦ã‚‚å¼·åˆ¶è¿½åŠ ')
    parser.add_argument('--category', help='--check-urlã¨çµ„ã¿åˆã‚ã›ã¦ã‚«ãƒ†ã‚´ãƒªæŒ‡å®š')

    args = parser.parse_args()

    checker = DuplicateChecker()

    if args.check_all:
        # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
        print("ğŸ” å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œä¸­...")
        all_entries = checker.get_all_entries()
        report = checker.generate_duplicate_report(all_entries)
        print(report)

    elif args.check_url:
        # URLé‡è¤‡ãƒã‚§ãƒƒã‚¯ã®ã¿
        category = args.category or 'restaurants'
        if category not in checker.category_files:
            print(f"âŒ ç„¡åŠ¹ãªã‚«ãƒ†ã‚´ãƒª: {category}")
            return

        print(f"ğŸ” URLé‡è¤‡ãƒã‚§ãƒƒã‚¯: {category}")
        result = checker.check_new_entry_duplicates(args.check_url, category)

        if 'error' in result:
            print(f"âŒ {result['error']}")
            return

        new_entry = result['new_entry']
        print(f"ğŸ“¥ URL: {args.check_url[:80]}...")
        print(f"ğŸª åº—èˆ—å: {new_entry.name}")
        if new_entry.cid:
            print(f"ğŸ“ CID: {new_entry.cid}")

        if result['has_duplicates']:
            print("\nğŸš¨ é‡è¤‡æ¤œå‡º:")
            for dup in result['cid_duplicates']:
                entry = dup['entry']
                print(f"  âŒ CIDé‡è¤‡: {entry.file_source}:{entry.line_number} â†’ {entry.name}")
            for dup in result['name_duplicates']:
                entry = dup['entry']
                print(f"  âš ï¸ åå‰é¡ä¼¼({dup['similarity']:.1%}): {entry.file_source}:{entry.line_number} â†’ {entry.name}")
        else:
            print("âœ… é‡è¤‡ãªã—")

    else:
        # è¿½åŠ ã‚³ãƒãƒ³ãƒ‰ã®å‡¦ç†
        _handle_add_commands(checker, args)

def _handle_add_commands(checker, args):
    """è¿½åŠ ã‚³ãƒãƒ³ãƒ‰ã®å‡¦ç†"""
    if args.restaurant:
        checker.add_with_duplicate_check('restaurants', args.restaurant, args.force)
    elif args.parking:
        checker.add_with_duplicate_check('parkings', args.parking, args.force)
    elif args.toilet:
        checker.add_with_duplicate_check('toilets', args.toilet, args.force)


if __name__ == '__main__':
    main()
