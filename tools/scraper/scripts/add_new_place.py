#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–°åº—èˆ—è¿½åŠ ã‚¯ã‚¤ãƒƒã‚¯ãƒ„ãƒ¼ãƒ«ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ä»˜ãï¼‰

ä½¿ç”¨ä¾‹:
    python scripts/add_new_place.py --restaurant "https://www.google.com/maps/place/..."
    python scripts/add_new_place.py --parking "https://www.google.com/maps/place/..."
    python scripts/add_new_place.py --toilet "https://www.google.com/maps/place/..."
    python scripts/add_new_place.py --workflow  # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›
    python scripts/add_new_place.py --check-duplicates  # é‡è¤‡ãƒã‚§ãƒƒã‚¯ã®ã¿
"""

import argparse
import sys
from pathlib import Path
from new_url_converter import AdvancedURLConverter


class NewPlaceManager:
    """æ–°åº—èˆ—è¿½åŠ ç®¡ç†ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.converter = AdvancedURLConverter()
        self.data_dir = Path('data')

        # ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°
        self.category_files = {
            'restaurants': self.data_dir / 'restaurants_merged.txt',
            'parkings': self.data_dir / 'parkings_merged.txt',
            'toilets': self.data_dir / 'toilets_merged.txt'
        }

        self.workflow_file = self.data_dir / 'new_places_workflow.txt'

    def add_to_category(self, category: str, url: str, check_duplicates: bool = True) -> bool:
        """ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚¡ã‚¤ãƒ«ã«ç›´æ¥è¿½åŠ ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰"""
        if category not in self.category_files:
            print(f"âŒ ç„¡åŠ¹ãªã‚«ãƒ†ã‚´ãƒª: {category}")
            return False

        file_path = self.category_files[category]

        if not file_path.exists():
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
            return False

        # é‡è¤‡ãƒã‚§ãƒƒã‚¯
        if check_duplicates:
            print("ğŸ” é‡è¤‡ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œä¸­...")
            if self._check_for_duplicates(url):
                response = input("é‡è¤‡ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/N): ").lower().strip()
                if response != 'y':
                    print("âŒ è¿½åŠ ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
                    return False

        # URLå¤‰æ›
        result = self.converter.convert_single_url(url)

        if not result['success']:
            print(f"âŒ URLå¤‰æ›å¤±æ•—: {result.get('error', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
            return False

        converted_line = result['converted']

        print(f"ğŸ”„ ã‚«ãƒ†ã‚´ãƒªãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½åŠ : {category}")
        print(f"ğŸ“¥ å…ƒURL: {url[:80]}...")
        print(f"ğŸ“¤ å¤‰æ›å¾Œ: {converted_line}")

        # ãƒ•ã‚¡ã‚¤ãƒ«ã«è¿½åŠ 
        try:
            with open(file_path, 'a', encoding='utf-8') as f:
                f.write(f"\n{converted_line}")

            print(f"âœ… è¿½åŠ å®Œäº†: {file_path.name}")

            # çµ±è¨ˆè¡¨ç¤º
            if result['cid']:
                print(f"ğŸ“ CID: {result['cid']}")
            if result['place_name']:
                print(f"ğŸª åº—èˆ—å: {result['place_name']}")

            return True

        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def _check_for_duplicates(self, url: str) -> bool:
        """é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # URLå¤‰æ›ã—ã¦ CID ã¨åå‰ã‚’å–å¾—
        result = self.converter.convert_single_url(url)
        if not result['success']:
            return False

        new_cid = result['cid']
        new_name = result['place_name']

        duplicates_found = False

        # å…¨ã‚«ãƒ†ã‚´ãƒªã‚’ãƒã‚§ãƒƒã‚¯
        for check_category, file_path in self.category_files.items():
            if file_path.exists():
                if self._check_file_for_duplicates(file_path, check_category, new_cid, new_name):
                    duplicates_found = True

        return duplicates_found

    def _check_file_for_duplicates(self, file_path, category: str, new_cid: str, new_name: str) -> bool:
        """æŒ‡å®šãƒ•ã‚¡ã‚¤ãƒ«å†…ã§ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            for line_num, line in enumerate(lines, 1):
                line = line.strip()
                if not line or line.startswith('#'):
                    continue

                # CID ãƒã‚§ãƒƒã‚¯
                if self._check_cid_duplicate(line, new_cid, category, line_num):
                    return True

                # åå‰ãƒã‚§ãƒƒã‚¯
                if self._check_name_duplicate(line, new_name, category, line_num):
                    return True

            return False

        except Exception as e:
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path.name}: {e}")
            return False

    def _check_cid_duplicate(self, line: str, new_cid: str, category: str, line_num: int) -> bool:
        """CIDé‡è¤‡ãƒã‚§ãƒƒã‚¯"""
        import re

        if new_cid and 'maps.google.com/place?cid=' in line:
            cid_match = re.search(r'cid=(\d+)', line)
            if cid_match and cid_match.group(1) == new_cid:
                name_match = re.search(r'#\s*(.+)', line)
                existing_name = name_match.group(1).strip() if name_match else "ä¸æ˜"
                print(f"âŒ CIDé‡è¤‡: {category}:{line_num} â†’ {existing_name}")
                return True
        return False

    def _check_name_duplicate(self, line: str, new_name: str, category: str, line_num: int) -> bool:
        """åå‰é‡è¤‡ãƒã‚§ãƒƒã‚¯"""
        from difflib import SequenceMatcher
        import re

        if not new_name:
            return False

        # æ—¢å­˜ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã®åå‰ã‚’æŠ½å‡º
        existing_name = self._extract_name_from_line(line)

        if existing_name:
            similarity = SequenceMatcher(None, new_name.lower(), existing_name.lower()).ratio()
            if similarity >= 0.8:
                print(f"âš ï¸ åå‰é¡ä¼¼({similarity:.1%}): {category}:{line_num} â†’ {existing_name}")
                return similarity >= 0.95  # 95%ä»¥ä¸Šã¯ç¢ºå®Ÿã«é‡è¤‡

        return False

    def _extract_name_from_line(self, line: str) -> str:
        """è¡Œã‹ã‚‰åå‰ã‚’æŠ½å‡º"""
        import re

        if '#' in line:
            name_match = re.search(r'#\s*(.+)', line)
            if name_match:
                return name_match.group(1).strip()
        elif not ('http' in line or 'maps.google.com' in line):
            # ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®å ´åˆ
            return line.strip()

        return ""

    def check_all_duplicates(self) -> None:
        """å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯"""
        print("ğŸ” å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œä¸­...")

        # å°‚ç”¨ã®é‡è¤‡ãƒã‚§ãƒƒã‚«ãƒ¼ã‚’ä½¿ç”¨
        try:
            from add_place_with_duplicate_check import DuplicateChecker
            checker = DuplicateChecker()
            all_entries = checker.get_all_entries()
            report = checker.generate_duplicate_report(all_entries)
            print(report)
        except ImportError:
            print("âŒ è©³ç´°ãªé‡è¤‡ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            print("ğŸ’¡ python scripts/add_place_with_duplicate_check.py --check-all ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")

    def convert_workflow_file(self) -> bool:
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›"""
        if not self.workflow_file.exists():
            print(f"âŒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.workflow_file}")
            return False

        print(f"ğŸ”„ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›: {self.workflow_file.name}")

        results = self.converter.convert_file(str(self.workflow_file))
        report = self.converter.generate_conversion_report(results)
        print(report)

        if results['success'] and results['cid_extractions']:
            print("\nğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
            print("1. å¤‰æ›ã•ã‚ŒãŸCID URLã‚’é©åˆ‡ãªã‚«ãƒ†ã‚´ãƒªãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚³ãƒ”ãƒ¼")
            print("2. ãƒ‡ãƒ¼ã‚¿åé›†ã‚’å®Ÿè¡Œ: python interface/cli/main.py --target [category] --mode standard")

        return results['success']

    def show_workflow_guide(self):
        """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¬ã‚¤ãƒ‰ã‚’è¡¨ç¤º"""
        guide = """
ğŸ¯ æ–°åº—èˆ—è¿½åŠ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

ã€æ–¹æ³•1: ç›´æ¥è¿½åŠ ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ä»˜ãï¼‰ã€‘
python scripts/add_new_place.py --restaurant "URL"
python scripts/add_new_place.py --parking "URL"
python scripts/add_new_place.py --toilet "URL"

ã€æ–¹æ³•2: é‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚¹ã‚­ãƒƒãƒ—ã§è¿½åŠ ã€‘
python scripts/add_new_place.py --restaurant "URL" --no-duplicate-check
python scripts/add_new_place.py --parking "URL" --no-duplicate-check
python scripts/add_new_place.py --toilet "URL" --no-duplicate-check

ã€æ–¹æ³•3: ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨ã€‘
1. data/new_places_workflow.txt ã«URLã‚’è¿½åŠ 
2. python scripts/add_new_place.py --workflow
3. å¤‰æ›ã•ã‚ŒãŸCIDã‚’é©åˆ‡ãªã‚«ãƒ†ã‚´ãƒªãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚³ãƒ”ãƒ¼

ã€é‡è¤‡ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã€‘
python scripts/add_new_place.py --check-duplicates  # å…¨ãƒ•ã‚¡ã‚¤ãƒ«é‡è¤‡ãƒã‚§ãƒƒã‚¯

ğŸ” é‡è¤‡ãƒã‚§ãƒƒã‚¯è©³ç´°:
- CIDãƒ™ãƒ¼ã‚¹ã®å®Œå…¨é‡è¤‡æ¤œå‡º
- åå‰ãƒ™ãƒ¼ã‚¹ã®é¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆ80%ä»¥ä¸Šã§è­¦å‘Šã€95%ä»¥ä¸Šã§é‡è¤‡åˆ¤å®šï¼‰
- å…¨ã‚«ãƒ†ã‚´ãƒªã‚’æ¨ªæ–­ã—ã¦ãƒã‚§ãƒƒã‚¯
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹ï¼ˆ--no-duplicate-checkã§ç„¡åŠ¹åŒ–å¯èƒ½ï¼‰

ã€ãƒ‡ãƒ¼ã‚¿åé›†å®Ÿè¡Œã€‘
python interface/cli/main.py --target restaurants --mode standard
python interface/cli/main.py --target parkings --mode standard
python interface/cli/main.py --target toilets --mode standard

ã€å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã€‘
- restaurants_merged.txt (é£²é£Ÿåº—)
- parkings_merged.txt (é§è»Šå ´)
- toilets_merged.txt (ãƒˆã‚¤ãƒ¬)
"""
        print(guide)


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description='æ–°åº—èˆ—è¿½åŠ ã‚¯ã‚¤ãƒƒã‚¯ãƒ„ãƒ¼ãƒ«',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument('--restaurant', help='ãƒ¬ã‚¹ãƒˆãƒ©ãƒ³URLã‚’ç›´æ¥è¿½åŠ ')
    group.add_argument('--parking', help='é§è»Šå ´URLã‚’ç›´æ¥è¿½åŠ ')
    group.add_argument('--toilet', help='ãƒˆã‚¤ãƒ¬URLã‚’ç›´æ¥è¿½åŠ ')
    group.add_argument('--workflow', action='store_true', help='ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›')
    group.add_argument('--guide', action='store_true', help='ä½¿ç”¨ã‚¬ã‚¤ãƒ‰ã‚’è¡¨ç¤º')
    group.add_argument('--check-duplicates', action='store_true', help='å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ')

    parser.add_argument('--no-duplicate-check', action='store_true',
                       help='é‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯é‡è¤‡ãƒã‚§ãƒƒã‚¯ãŒæœ‰åŠ¹ï¼‰')

    args = parser.parse_args()

    manager = NewPlaceManager()

    # é‡è¤‡ãƒã‚§ãƒƒã‚¯è¨­å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ‰åŠ¹ã€--no-duplicate-checkã§ç„¡åŠ¹åŒ–ï¼‰
    check_duplicates = not args.no_duplicate_check

    if args.guide:
        manager.show_workflow_guide()
    elif args.workflow:
        manager.convert_workflow_file()
    elif args.check_duplicates:
        manager.check_all_duplicates()
    elif args.restaurant:
        manager.add_to_category('restaurants', args.restaurant, check_duplicates)
    elif args.parking:
        manager.add_to_category('parkings', args.parking, check_duplicates)
    elif args.toilet:
        manager.add_to_category('toilets', args.toilet, check_duplicates)


if __name__ == '__main__':
    main()
