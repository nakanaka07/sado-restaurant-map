#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½æ¸¡é£²é£Ÿåº—ãƒãƒƒãƒ— - ã‚³ã‚¹ãƒˆæœ€é©åŒ–å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ®µéšçš„å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã«ã‚ˆã‚‹APIåˆ©ç”¨æ–™é‡‘å‰Šæ¸›

ğŸ†• æ–°æ©Ÿèƒ½: ä½æ¸¡å¸‚å†…ãƒ»ä½æ¸¡å¸‚å¤–ãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•åˆ†é›¢
å®Ÿè¡Œå¾Œã«è‡ªå‹•çš„ã«ä½æ¸¡å¸‚å¤–ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ¥ã‚·ãƒ¼ãƒˆã«ç§»å‹•ã—ã¾ã™ã€‚

ä½¿ç”¨ä¾‹:
    # é€šå¸¸å®Ÿè¡Œï¼ˆä½æ¸¡å¸‚å†…ãƒ»ä½æ¸¡å¸‚å¤–åˆ†é›¢ã‚ã‚Šï¼‰
    python run_optimized.py --mode=standard
    
    # åˆ†é›¢æ©Ÿèƒ½ã‚’ç„¡åŠ¹åŒ–
    python run_optimized.py --mode=standard --no-separate
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†é›¢ã®ã¿å®Ÿè¡Œï¼ˆPlaces API ã¯å‘¼ã°ãªã„ï¼‰
    python run_optimized.py --separate-only
    
    # ç‰¹å®šã‚«ãƒ†ã‚´ãƒªã®ã¿å‡¦ç†
    python run_optimized.py --target=restaurants --mode=quick

ä½œæˆã•ã‚Œã‚‹ã‚·ãƒ¼ãƒˆ:
    - é£²é£Ÿåº—_ä½æ¸¡å¸‚å¤–
    - é§è»Šå ´_ä½æ¸¡å¸‚å¤–  
    - å…¬è¡†ãƒˆã‚¤ãƒ¬_ä½æ¸¡å¸‚å¤–
"""

import os
import sys
import argparse
import gspread
import pandas as pd
from datetime import datetime
from dotenv import load_dotenv

# å…ƒã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from places_data_updater import main as original_main, load_queries_from_file, authenticate_google_sheets
    from improved_search_strategy import ImprovedSearchStrategy
except ImportError:
    print("âŒ å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    sys.exit(1)

class CostOptimizedRunner:
    """ã‚³ã‚¹ãƒˆæœ€é©åŒ–å®Ÿè¡Œã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.strategy = ImprovedSearchStrategy()
        
        # å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰è¨­å®š
        self.execution_modes = {
            'quick': {
                'description': 'é«˜ç¢ºç‡ã‚¯ã‚¨ãƒªã®ã¿å®Ÿè¡Œï¼ˆç´„30%ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼‰',
                'max_queries_per_category': 50,
                'skip_difficult': True,
                'estimated_cost_usd': 3.00,
                'priority_keywords': ['ä½æ¸¡', 'ä¸¡æ´¥', 'ç›¸å·', 'æœ¬åº—', 'è€èˆ—']
            },
            'standard': {
                'description': 'æœ€é©åŒ–ã•ã‚ŒãŸå…¨ã‚¯ã‚¨ãƒªå®Ÿè¡Œï¼ˆæ¨å¥¨ï¼‰',
                'max_queries_per_category': -1,
                'skip_difficult': True,
                'estimated_cost_usd': 7.95,
                'priority_keywords': []
            },
            'comprehensive': {
                'description': 'å¾“æ¥é€šã‚Šã®å…¨ä»¶å®Ÿè¡Œ',
                'max_queries_per_category': -1,
                'skip_difficult': False,
                'estimated_cost_usd': 11.65,
                'priority_keywords': []
            }
        }
    
    def separate_by_location(self, spreadsheet_id=None):
        """
        ãƒ‡ãƒ¼ã‚¿ã‚’ä½æ¸¡å¸‚å†…ãƒ»ä½æ¸¡å¸‚å¤–ã«åˆ†ã‘ã¦åˆ¥ã‚·ãƒ¼ãƒˆã«å‡ºåŠ›
        ç·¯åº¦çµŒåº¦ã«ã‚ˆã‚‹ç²¾å¯†ãªåœ°åŸŸåˆ¤å®šã‚’å®Ÿè£…
        """
        print("\nğŸ”„ ãƒ‡ãƒ¼ã‚¿ã®åœ°åŸŸåˆ¥åˆ†é›¢å‡¦ç†ã‚’é–‹å§‹...")
        print("ğŸ“ ç·¯åº¦çµŒåº¦ã«ã‚ˆã‚‹ç²¾å¯†ãªä½æ¸¡å³¶åˆ¤å®šã‚’ä½¿ç”¨")
        
        # ä½æ¸¡å³¶å†…åˆ¤å®šã®ãŸã‚ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        try:
            from places_data_updater import (
                is_within_sado_bounds, 
                classify_district_by_coordinates, 
                normalize_address, 
                classify_district
            )
        except ImportError:
            print("âŒ å¿…è¦ãªåˆ¤å®šé–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return False
        
        # Google Sheetsèªè¨¼
        gc = authenticate_google_sheets()
        if not gc:
            print("âŒ Google Sheetsèªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        try:
            if not spreadsheet_id:
                spreadsheet_id = os.environ.get('SPREADSHEET_ID')
            
            spreadsheet = gc.open_by_key(spreadsheet_id)
            
            # å¯¾è±¡ã‚·ãƒ¼ãƒˆå
            target_sheets = ['é£²é£Ÿåº—', 'é§è»Šå ´', 'å…¬è¡†ãƒˆã‚¤ãƒ¬']
            
            for sheet_name in target_sheets:
                try:
                    print(f"ğŸ“Š {sheet_name}ã‚·ãƒ¼ãƒˆã‚’å‡¦ç†ä¸­...")
                    
                    # å…ƒã®ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    try:
                        worksheet = spreadsheet.worksheet(sheet_name)
                    except gspread.WorksheetNotFound:
                        print(f"âš ï¸ {sheet_name}ã‚·ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        continue
                    
                    # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    try:
                        data = worksheet.get_all_records()
                    except Exception as e:
                        if "duplicates" in str(e).lower():
                            print(f"âš ï¸ {sheet_name}ã‚·ãƒ¼ãƒˆã§ãƒ˜ãƒƒãƒ€ãƒ¼é‡è¤‡ã‚¨ãƒ©ãƒ¼ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                            continue
                        else:
                            raise e
                    
                    if not data:
                        print(f"âš ï¸ {sheet_name}ã‚·ãƒ¼ãƒˆã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        continue
                    
                    # DataFrameã«å¤‰æ›
                    df = pd.DataFrame(data)
                    
                    # ä½æ‰€åˆ—ã¨ç·¯åº¦çµŒåº¦åˆ—ã®å­˜åœ¨ç¢ºèª
                    address_column = None
                    for col in ['ä½æ‰€', 'æ‰€åœ¨åœ°', 'address']:
                        if col in df.columns:
                            address_column = col
                            break
                    
                    lat_column = None
                    lng_column = None
                    for col in ['ç·¯åº¦', 'latitude', 'lat']:
                        if col in df.columns:
                            lat_column = col
                            break
                    for col in ['çµŒåº¦', 'longitude', 'lng', 'lon']:
                        if col in df.columns:
                            lng_column = col
                            break
                    
                    if not address_column:
                        print(f"âš ï¸ {sheet_name}ã‚·ãƒ¼ãƒˆã«ä½æ‰€æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                        continue
                    
                    # æ”¹è‰¯ã•ã‚ŒãŸä½æ¸¡å³¶å†…åˆ¤å®š
                    sado_indices = []
                    non_sado_indices = []
                    coord_fixed_count = 0
                    
                    for i, row in df.iterrows():
                        address = str(row.get(address_column, ''))
                        lat = row.get(lat_column, '') if lat_column else ''
                        lng = row.get(lng_column, '') if lng_column else ''
                        
                        is_sado = False
                        
                        # ç·¯åº¦çµŒåº¦ã«ã‚ˆã‚‹åˆ¤å®šï¼ˆæœ€å„ªå…ˆï¼‰
                        if lat and lng:
                            try:
                                lat_float = float(lat)
                                lng_float = float(lng)
                                if is_within_sado_bounds(lat_float, lng_float):
                                    is_sado = True
                                    # ä½æ‰€ã«ä½æ¸¡å¸‚ãŒå«ã¾ã‚Œã¦ã„ãªã„ãŒç·¯åº¦çµŒåº¦ã§ä½æ¸¡å³¶å†…ã¨åˆ¤å®šã•ã‚ŒãŸå ´åˆ
                                    if 'ä½æ¸¡å¸‚' not in address and 'ä½æ¸¡' not in address:
                                        coord_fixed_count += 1
                                        print(f"   ğŸ“ ç·¯åº¦çµŒåº¦ã«ã‚ˆã‚Šä½æ¸¡å³¶å†…ã¨åˆ¤å®š: {row.get('åº—èˆ—å', row.get('åç§°', 'unknown'))}")
                            except (ValueError, TypeError):
                                pass
                        
                        # ç·¯åº¦çµŒåº¦ãŒãªã„/ç„¡åŠ¹ãªå ´åˆã¯ä½æ‰€ã«ã‚ˆã‚‹åˆ¤å®š
                        if not is_sado:
                            # ä½æ¸¡é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
                            sado_keywords = ['ä½æ¸¡å¸‚', 'ä½æ¸¡', 'æ–°æ½ŸçœŒä½æ¸¡', 'ä¸¡æ´¥', 'ç›¸å·', 'ä½å’Œç”°', 'é‡‘äº•', 'æ–°ç©‚', 'ç•‘é‡', 'çœŸé‡', 'å°æœ¨', 'ç¾½èŒ‚', 'èµ¤æ³Š']
                            is_sado = any(keyword in address for keyword in sado_keywords)
                        
                        if is_sado:
                            sado_indices.append(i)
                        else:
                            non_sado_indices.append(i)
                    
                    sado_data = df.iloc[sado_indices] if sado_indices else pd.DataFrame()
                    non_sado_data = df.iloc[non_sado_indices] if non_sado_indices else pd.DataFrame()
                    
                    print(f"   ğŸ“Š ä½æ¸¡å¸‚å†…: {len(sado_data)}ä»¶")
                    print(f"   ğŸ“Š ä½æ¸¡å¸‚å¤–: {len(non_sado_data)}ä»¶")
                    if coord_fixed_count > 0:
                        print(f"   ğŸ“ ç·¯åº¦çµŒåº¦ã«ã‚ˆã‚Šä¿®æ­£: {coord_fixed_count}ä»¶")
                    
                    # ä½æ¸¡å¸‚å¤–ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿å‡¦ç†
                    if len(non_sado_data) > 0:
                        # ä½æ¸¡å¸‚å¤–ã‚·ãƒ¼ãƒˆã‚’ä½œæˆã¾ãŸã¯æ›´æ–°
                        non_sado_sheet_name = f"{sheet_name}_ä½æ¸¡å¸‚å¤–"
                        
                        try:
                            non_sado_worksheet = spreadsheet.worksheet(non_sado_sheet_name)
                            # æ—¢å­˜ã‚·ãƒ¼ãƒˆã‚’ã‚¯ãƒªã‚¢
                            non_sado_worksheet.clear()
                            print(f"   ğŸ“ æ—¢å­˜ã®{non_sado_sheet_name}ã‚·ãƒ¼ãƒˆã‚’æ›´æ–°")
                        except gspread.WorksheetNotFound:
                            # æ–°ã—ã„ã‚·ãƒ¼ãƒˆã‚’ä½œæˆ
                            non_sado_worksheet = spreadsheet.add_worksheet(
                                title=non_sado_sheet_name, 
                                rows=len(non_sado_data) + 10, 
                                cols=len(df.columns)
                            )
                            print(f"   âœ¨ {non_sado_sheet_name}ã‚·ãƒ¼ãƒˆã‚’æ–°è¦ä½œæˆ")
                        
                        # ä½æ¸¡å¸‚å¤–ãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿
                        if len(non_sado_data) > 0:
                            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’å«ã‚ã¦ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
                            output_data = [list(df.columns)] + non_sado_data.values.tolist()
                            non_sado_worksheet.update(values=output_data, range_name='A1')
                            
                            print(f"   âœ… {len(non_sado_data)}ä»¶ã®ä½æ¸¡å¸‚å¤–ãƒ‡ãƒ¼ã‚¿ã‚’{non_sado_sheet_name}ã‚·ãƒ¼ãƒˆã«å‡ºåŠ›")
                            
                            # ä½æ¸¡å¸‚å¤–ã®åº—èˆ—ãƒªã‚¹ãƒˆã‚’è¡¨ç¤º
                            print(f"   ğŸ“ ä½æ¸¡å¸‚å¤–ã®{sheet_name}:")
                            for idx, row in non_sado_data.iterrows():
                                name = row.get('åº—èˆ—å', row.get('é§è»Šå ´å', row.get('æ–½è¨­å', 'åç§°ä¸æ˜')))
                                address = row.get(address_column, 'ä½æ‰€ä¸æ˜')
                                print(f"      - {name} ({address})")
                        
                        # å…ƒã®ã‚·ãƒ¼ãƒˆã‚’ä½æ¸¡å¸‚å†…ãƒ‡ãƒ¼ã‚¿ã®ã¿ã«æ›´æ–°
                        if len(sado_data) > 0:
                            worksheet.clear()
                            sado_output_data = [list(df.columns)] + sado_data.values.tolist()
                            worksheet.update(values=sado_output_data, range_name='A1')
                            print(f"   ğŸ  å…ƒã®{sheet_name}ã‚·ãƒ¼ãƒˆã‚’ä½æ¸¡å¸‚å†…ãƒ‡ãƒ¼ã‚¿({len(sado_data)}ä»¶)ã«æ›´æ–°")
                        else:
                            print(f"   âš ï¸ {sheet_name}ã«ä½æ¸¡å¸‚å†…ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                    else:
                        print(f"   âœ… {sheet_name}ã¯å…¨ã¦ä½æ¸¡å¸‚å†…ãƒ‡ãƒ¼ã‚¿ã§ã™")
                
                except Exception as e:
                    print(f"âŒ {sheet_name}ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
                    continue
            
            print("\nâœ… åœ°åŸŸåˆ¥ãƒ‡ãƒ¼ã‚¿åˆ†é›¢å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿åˆ†é›¢å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
            return False
    
    def filter_queries_by_mode(self, queries, mode, category):
        """å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã«åŸºã¥ã„ã¦ã‚¯ã‚¨ãƒªã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        config = self.execution_modes[mode]
        
        if not config['skip_difficult']:
            # comprehensive ãƒ¢ãƒ¼ãƒ‰: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãªã—
            return queries
        
        filtered_queries = []
        
        for query in queries:
            # ã‚¹ã‚­ãƒƒãƒ—å¯¾è±¡ãƒã‚§ãƒƒã‚¯
            if self.strategy.should_skip_search(query):
                continue
            
            # quick ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            if mode == 'quick':
                # å„ªå…ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚€ã‚¯ã‚¨ãƒªã‚’å„ªå…ˆ
                has_priority = any(keyword in query for keyword in config['priority_keywords'])
                
                # çŸ­ã™ãã‚‹ã‚¯ã‚¨ãƒªã¯é™¤å¤–
                if len(query.replace(' ', '')) < 3:
                    continue
                
                # è¤‡é›‘ã™ãã‚‹ã‚¯ã‚¨ãƒªã¯é™¤å¤–ï¼ˆquick ãƒ¢ãƒ¼ãƒ‰ã§ã¯ï¼‰
                if len(query) > 20 and not has_priority:
                    continue
                
                # å„ªå…ˆã‚¯ã‚¨ãƒªã¾ãŸã¯ä¸Šä½Nä»¶ã¾ã§
                if has_priority or len(filtered_queries) < config['max_queries_per_category']:
                    filtered_queries.append(query)
            else:
                filtered_queries.append(query)
        
        # æœ€å¤§ä»¶æ•°åˆ¶é™
        max_queries = config['max_queries_per_category']
        if max_queries > 0:
            return filtered_queries[:max_queries]
        
        return filtered_queries
    
    def estimate_cost(self, mode, target_data='all'):
        """å®Ÿè¡Œã‚³ã‚¹ãƒˆã‚’è¦‹ç©ã‚‚ã‚Š"""
        query_files = {
            'restaurants': 'restaurants.txt',
            'parkings': 'parkings.txt', 
            'toilets': 'toilets.txt'
        }
        
        # TARGET_DATAã«ã‚ˆã‚‹çµã‚Šè¾¼ã¿
        if target_data != 'all':
            category_mapping = {
                'restaurants': 'restaurants',
                'parkings': 'parkings',
                'toilets': 'toilets'
            }
            if target_data in category_mapping:
                query_files = {category_mapping[target_data]: query_files[category_mapping[target_data]]}
        
        total_queries = 0
        
        for category, filename in query_files.items():
            queries = load_queries_from_file(filename)
            filtered = self.filter_queries_by_mode(queries, mode, category)
            total_queries += len(filtered)
        
        # APIå‘¼ã³å‡ºã—æ•°ã‚’è¦‹ç©ã‚‚ã‚Šï¼ˆå¹³å‡2.1å›/ã‚¯ã‚¨ãƒªï¼‰
        estimated_api_calls = total_queries * 2.1
        estimated_cost = estimated_api_calls * 0.017  # Text Search APIæ–™é‡‘
        
        return {
            'total_queries': total_queries,
            'estimated_api_calls': int(estimated_api_calls),
            'estimated_cost_usd': estimated_cost,
            'mode_description': self.execution_modes[mode]['description']
        }
    
    def run_optimized(self, mode='standard', target_data='all', dry_run=False, separate_location=True):
        """æœ€é©åŒ–ã•ã‚ŒãŸå®Ÿè¡Œ"""
        print(f"ğŸš€ ã‚³ã‚¹ãƒˆæœ€é©åŒ–å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: {mode}")
        
        # ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š
        estimation = self.estimate_cost(mode, target_data)
        print(f"ğŸ“Š å®Ÿè¡Œè¦‹ç©ã‚‚ã‚Š:")
        print(f"   - ãƒ¢ãƒ¼ãƒ‰: {estimation['mode_description']}")
        print(f"   - å‡¦ç†ã‚¯ã‚¨ãƒªæ•°: {estimation['total_queries']}")
        print(f"   - äºˆæƒ³APIå‘¼ã³å‡ºã—: {estimation['estimated_api_calls']}")
        print(f"   - äºˆæƒ³ã‚³ã‚¹ãƒˆ: ${estimation['estimated_cost_usd']:.3f} USD")
        
        if separate_location:
            print(f"   - å¾Œå‡¦ç†: ä½æ¸¡å¸‚å†…ãƒ»ä½æ¸¡å¸‚å¤–ãƒ‡ãƒ¼ã‚¿ã®è‡ªå‹•åˆ†é›¢")
        
        if dry_run:
            print("ğŸ’¡ ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Œäº†ï¼ˆå®Ÿéš›ã®å®Ÿè¡Œã¯è¡Œã„ã¾ã›ã‚“ã§ã—ãŸï¼‰")
            return
        
        # å®Ÿè¡Œç¢ºèª
        user_input = input("\nå®Ÿè¡Œã‚’ç¶šã‘ã¾ã™ã‹ï¼Ÿ (y/N): ")
        if user_input.lower() not in ['y', 'yes']:
            print("âŒ å®Ÿè¡Œã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            return
        
        # ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¦ãƒ¢ãƒ¼ãƒ‰æƒ…å ±ã‚’æ¸¡ã™
        os.environ['EXECUTION_MODE'] = mode
        os.environ['TARGET_DATA'] = target_data
        
        print(f"\nâœ… å®Ÿè¡Œé–‹å§‹...")
        
        # å…ƒã®ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚’å®Ÿè¡Œ
        try:
            original_main()
            
            # åœ°åŸŸåˆ¥ãƒ‡ãƒ¼ã‚¿åˆ†é›¢å‡¦ç†
            if separate_location:
                self.separate_by_location()
                
        except Exception as e:
            print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description='ä½æ¸¡é£²é£Ÿåº—ãƒãƒƒãƒ— - ã‚³ã‚¹ãƒˆæœ€é©åŒ–å®Ÿè¡Œ')
    parser.add_argument('--mode', choices=['quick', 'standard', 'comprehensive'], 
                       default='standard', help='å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰')
    parser.add_argument('--target', choices=['all', 'restaurants', 'parkings', 'toilets'],
                       default='all', help='å¯¾è±¡ãƒ‡ãƒ¼ã‚¿')
    parser.add_argument('--dry-run', action='store_true', help='ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼ˆè¦‹ç©ã‚‚ã‚Šã®ã¿ï¼‰')
    parser.add_argument('--estimate-only', action='store_true', help='ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Šã®ã¿è¡¨ç¤º')
    parser.add_argument('--no-separate', action='store_true', help='ä½æ¸¡å¸‚å†…ãƒ»ä½æ¸¡å¸‚å¤–ã®è‡ªå‹•åˆ†é›¢ã‚’ç„¡åŠ¹åŒ–')
    parser.add_argument('--separate-only', action='store_true', help='ãƒ‡ãƒ¼ã‚¿åˆ†é›¢ã®ã¿å®Ÿè¡Œï¼ˆPlaces API ã¯å‘¼ã°ãªã„ï¼‰')
    
    args = parser.parse_args()
    
    runner = CostOptimizedRunner()
    
    if args.separate_only:
        # ãƒ‡ãƒ¼ã‚¿åˆ†é›¢ã®ã¿å®Ÿè¡Œ
        print("ğŸ”„ ãƒ‡ãƒ¼ã‚¿åˆ†é›¢å‡¦ç†ã®ã¿å®Ÿè¡Œã—ã¾ã™...")
        runner.separate_by_location()
        return
    
    if args.estimate_only:
        # å…¨ãƒ¢ãƒ¼ãƒ‰ã®è¦‹ç©ã‚‚ã‚Šã‚’è¡¨ç¤º
        print("ğŸ’° å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰åˆ¥ã‚³ã‚¹ãƒˆè¦‹ç©ã‚‚ã‚Š\n")
        for mode in ['quick', 'standard', 'comprehensive']:
            estimation = runner.estimate_cost(mode, args.target)
            print(f"ğŸ“‹ {mode.upper()}ãƒ¢ãƒ¼ãƒ‰:")
            print(f"   {estimation['mode_description']}")
            print(f"   ã‚¯ã‚¨ãƒªæ•°: {estimation['total_queries']}")
            print(f"   APIå‘¼ã³å‡ºã—: {estimation['estimated_api_calls']}")
            print(f"   ã‚³ã‚¹ãƒˆ: ${estimation['estimated_cost_usd']:.3f} USD\n")
    else:
        separate_location = not args.no_separate
        runner.run_optimized(args.mode, args.target, args.dry_run, separate_location)

if __name__ == '__main__':
    main()
